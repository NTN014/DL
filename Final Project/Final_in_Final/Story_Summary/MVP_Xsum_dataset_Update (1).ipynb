{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f93eb527223f4970a7dc5bfe5aa12289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_827ef72aeda74498875ad3c876bee7db",
              "IPY_MODEL_6cb15f3a68004205855a3106e4c51367",
              "IPY_MODEL_c1509e9e47e94257a00c2e833ea7da20"
            ],
            "layout": "IPY_MODEL_d3ba93daeb384d0dbecf00829ea95d05"
          }
        },
        "827ef72aeda74498875ad3c876bee7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f250d7e114a4b5e8c3090afd269af1f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a85556e244824f96bc1f79a98ddb2453",
            "value": "Map: 100%"
          }
        },
        "6cb15f3a68004205855a3106e4c51367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba54680dbe1f4a7896640de654931a4a",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2b7e86e51a74717bc6f0c6a3d4b754e",
            "value": 90
          }
        },
        "c1509e9e47e94257a00c2e833ea7da20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb456a282d934b729d4f6c024fc4a95d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_344fb5e6ef7e4b1484cdd3d2ff536580",
            "value": " 90/90 [00:00&lt;00:00, 157.08 examples/s]"
          }
        },
        "d3ba93daeb384d0dbecf00829ea95d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2f250d7e114a4b5e8c3090afd269af1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85556e244824f96bc1f79a98ddb2453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba54680dbe1f4a7896640de654931a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b7e86e51a74717bc6f0c6a3d4b754e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb456a282d934b729d4f6c024fc4a95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "344fb5e6ef7e4b1484cdd3d2ff536580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47cab4ed1faf49dc846da6fdacdc012a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58833013367c4674afa21c77bdb3f189",
              "IPY_MODEL_7b1865d2caf84bb0bfd557ab1a366390",
              "IPY_MODEL_17b7be62b0c24bc1b127cda8f07e6754"
            ],
            "layout": "IPY_MODEL_ca43edcaa59e434eb4597fcf475d3dbe"
          }
        },
        "58833013367c4674afa21c77bdb3f189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3efc66015b1f418b929bf028a318de2c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0a4e5d820b2d475d9fc986b2f0dca008",
            "value": "Map: 100%"
          }
        },
        "7b1865d2caf84bb0bfd557ab1a366390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_750ef68192624c02aaa7a5f52be88aea",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40840bc04f574e729688bbd9c8c9f895",
            "value": 10
          }
        },
        "17b7be62b0c24bc1b127cda8f07e6754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa027c7fccc744c3904997d2d37a763e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cd33a8c68f3a4edf9a603567a7f66a50",
            "value": " 10/10 [00:00&lt;00:00, 98.35 examples/s]"
          }
        },
        "ca43edcaa59e434eb4597fcf475d3dbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "3efc66015b1f418b929bf028a318de2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a4e5d820b2d475d9fc986b2f0dca008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "750ef68192624c02aaa7a5f52be88aea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40840bc04f574e729688bbd9c8c9f895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa027c7fccc744c3904997d2d37a763e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd33a8c68f3a4edf9a603567a7f66a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiNIXwQVkYJT",
        "outputId": "749a9dde-9e8f-40cb-9185-7f8ef15830ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets -qq\n",
        "!pip install transformers -qq\n",
        "!pip install rouge_score evaluate nltk -qq\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")"
      ],
      "metadata": {
        "id": "38bV9bfCkg2M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import datasets\n",
        "import evaluate\n",
        "import nltk\n",
        "import torch\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "3-GPcSgQkoWH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "S3bbM8dekpgF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MvpForConditionalGeneration, MvpTokenizerFast"
      ],
      "metadata": {
        "id": "0AfMxXzPB9nk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"t5-small\"\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
        "\n",
        "tokenizer = MvpTokenizerFast.from_pretrained(\"RUCAIBox/mvp\")\n",
        "model = MvpForConditionalGeneration.from_pretrained(\"RUCAIBox/mvp-summarization\")"
      ],
      "metadata": {
        "id": "Gt-xBDgekqwI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "metric = load_metric(\"rouge\")\n",
        "\n",
        "# Load the XSum dataset\n",
        "raw_datasets = load_dataset('xsum', split=\"train[:100]\")\n",
        "raw_datasets = raw_datasets.train_test_split(test_size=0.1)\n",
        "raw_datasets\n",
        "# raw_datasets[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgK0QDdDkxUj",
        "outputId": "5206e789-287a-4111-f992-66f24df2b0ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-d33476f077a5>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"rouge\")\n",
            "WARNING:datasets.builder:Found cached dataset xsum (/root/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 90\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['document', 'summary', 'id'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_random_elements(dataset, num_examples=5):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "sH8viw9Mkyup"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_elements(raw_datasets[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ax4dTW7Okz8a",
        "outputId": "9535c023-bb7b-411b-99ee-4381fe3dc0a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>summary</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>His departure was said to be one recommendation of a report  by former US Attorney-General Eric Holder about the company's culture and practices.\\nUber said the board had voted unanimously to adopt all the report's recommendations.\\nHowever, its contents will not be released until Tuesday.\\nMr Holder was asked to undertake the review in February after former Uber engineer Susan Fowler made claims of sexual harassment.\\nThe Financial Times reported that neither Uber nor Mr Michael would comment on whether he had resigned or been fired.\\nJames Cakmak, an analyst at Monness Crespi Hardt, said Mr Michael's departure reflected Uber's need for a \"fall guy\" and could help protect Mr Kalanick.\\n\"If Kalanick did leave, we think it would be very difficult for him to come back,\" Mr Cakmak told Bloomberg.\\nIt is possible Mr Kalanick could be forced to take a leave of absence or have his role altered. That issue was on the agenda at a seven-hour board meeting held in Los Angeles on Sunday.\\nMr Kalanick has been on bereavement leave following the death of his mother in a boating accident.\\nAn Uber insider said the recommendations in Mr Holder's report include introducing more control on spending, human resources and other areas where executives led by Mr Kalanick have had an unusual degree of autonomy for a company of Uber's size.\\nThe San Francisco-based ride-hailing service has more than 12,000 employees.\\nMr Kalanick has earned a reputation as an abrasive leader and was criticised earlier this year after being caught on video berating an Uber driver.\\nHe said in response to the video: \"I must fundamentally change as a leader and grow up.\"\\nUber board member Arianna Huffington has said Mr Kalanick needed to change his leadership style from that of a \"scrappy entrepreneur\" to be more like a \"leader of a major global company\".\\nOne Uber investor said the board's decisions were a step in the right direction, giving the firm an \"opportunity to reboot\".\\nJan Dawson, an analyst with Jackdaw Research, said: \"This week we finally learn just how committed Travis Kalanick and the rest of the senior leadership team at Uber is  to meaningful cultural change.\"\\nLast week Uber said it fired 20 staff after another law firm examined more than 200 cases including complaints about sexual harassment, discrimination and bullying.\\nAs part of its attempt to draw a line under its recent problems, Uber said it had appointed Wan Ling Martello, a Nestle executive and Alibaba board member, as an independent director.\\nShe is the third high-profile female appointment to the company in the past week.\\nUber, which is still privately owned with voting control resting with Mr Kalanick and his two board allies, is valued at about $68bn. Although revenues hit $6.5bn last year, it is yet to make a profit.</td>\n",
              "      <td>Emil Michael, Uber's senior vice-president and a close ally of chief executive Travis Kalanick, has left the company, employees have been told.</td>\n",
              "      <td>40254388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mr Mosley wants Google to block photos of him at a sex party first printed in the now-defunct News of the World, which he successfully sued in 2008.\\nHe is suing the internet firm for breaches of the Data Protection Act and misusing private information.\\nGoogle's barrister argued that Mr Mosley no longer has a \"reasonable expectation of privacy\".\\nMr Mosley won damages from the News of the World after it published a story alleging he had organised a Nazi-themed orgy.\\nPhotographs and a video which show his private sexual activity were originally obtained by News Group Newspapers Limited (NGN) in a clandestine \"sting\" operation.\\nMr Mosley - the son of 1930s fascist leader Sir Oswald Mosley - won Ã‚Â£60,000 after a judge ruled there was no substance to the allegation that there had been a Nazi theme to the sex party and found that his privacy had been breached.\\nIn that ruling, the High Court also said the article was not in the public interest.\\nMr Mosley has said the role-play at a rented Chelsea basement flat was harmless, consensual and private.\\nOn launching his legal action last year, Mr Mosley urged: \"Google should operate within the law rather than according to rules it makes itself. It cannot be allowed to ignore judgements in our courts.\"\\nGoogle has said it will remove URLs that it is alerted to, but is not prepared to remove the images entirely from its search engines.\\nIn court on Wednesday, Google's barrister Antony White QC for Google conceded that it was technically possible to remove the images and was \"not burdensome\" to do so.\\nHowever, he argued that Google was not the publisher of the private information, and that Mr Mosley no longer had a reasonable expectation of privacy in relation to the images.\\nOn that basis, Google will seek to show that Mr Mosley's claim is unfounded.\\nThe hearing is due to conclude on Thursday.</td>\n",
              "      <td>Google has asked the High Court to throw out legal action being taken by ex-Formula 1 boss Max Mosley.</td>\n",
              "      <td>30816523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The IPC opened proceedings against the National Paralympic Committee of Russia after a report claimed the country had operated a widespread doping programme.\\nA decision on any ban will come in the week commencing 1 August.\\nThe International Olympic Committee (IOC) has opted against a blanket ban.\\n\"I can assure you that our board will take the right decision in the interest of sport and the interest of the Paralympic movement moving forward,\" said Craven.\\nOn Sunday, the IOC said it would leave it up to the governing bodies of individual sports to decide if Russian competitors are clean and should be allowed to take part.\\nBut Craven, himself a member of the IOC, was critical of that decision and said the IPC would not necessarily follow suit.\\n\"I am disappointed in their decision, but that is a personal view,\" he added.\\n\"We have to acknowledge their right to take such a decision. This is ultra-serious. I don't think there has been a situation in the past where you have had institutional doping on such a scale.\\n\"We believe the Russian NPC is either unwilling or unable to uphold the IPC anti-doping code, which is in line with the World Anti-Doping Agency code, so that is what they have to respond to.\"\\nCanadian law professor Richard McLaren's report, published last week, claimed Russia operated a state-sponsored doping programme from 2011 to 2015.\\nThe IPC said it acted after McLaren provided the names of the athletes associated with the 35 \"disappearing positive samples\" from the Moscow laboratory highlighted in the report.\\nNineteen samples potentially doctored as part of the sample-swapping regime during the 2014 Sochi Paralympic Winter Games have been sent for further analysis.\\nRussia will have up to 21 days to appeal against any IPC decision, with the Rio Paralympics due to begin on 7 September.</td>\n",
              "      <td>The International Paralympic Committee will make its decision on Russia's participation in the Rio Games \"in the interest of sport\", president Sir Philip Craven has told BBC Sport.</td>\n",
              "      <td>36888270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gundogan, 26, told BBC Sport he \"can see the finishing line\" after tearing cruciate knee ligaments in December, but will not rush his return.\\nThe German missed the 2014 World Cup following back surgery that kept him out for a year, and sat out Euro 2016 because of a dislocated kneecap.\\nHe said: \"It is heavy mentally to accept that.\"\\nGundogan will not be fit for the start of the Premier League season at Brighton on 12 August but said his recovery time is now being measured in \"weeks\" rather than months.\\nHe told BBC Sport: \"It is really hard always to fall and fight your way back. You feel good and feel ready, then you get the next kick.\\n\"The worst part is behind me now. I want to feel ready when I am fully back. I want to feel safe and confident. I don't mind if it is two weeks or six.\"\\nGundogan made 15 appearances and scored five goals in his debut season for City following his Â£20m move from Borussia Dortmund.\\nHe is eager to get on the field again and was impressed at the club's 4-1 win over Real Madrid in a pre-season game in Los Angeles on Wednesday.\\nManager Pep Guardiola has made five new signings already this summer and continues to have an interest in Arsenal forward Alexis Sanchez and Monaco's Kylian Mbappe.\\nGundogan said: \"Optimism for the season is big. It is huge, definitely.\\n\"We felt that last year as well but it was a completely new experience for all of us. We know the Premier League a bit more now and can't wait for the season to start.\"\\nCity complete their three-match tour of the United States against Tottenham in Nashville on Saturday.\\nChelsea manager Antonio Conte said earlier this week he did not feel Tottenham were judged by the same standards as his own side, City and Manchester United.\\nSpurs have had the advantage in their recent meetings with City, winning three and drawing one of their last four Premier League games.\\nAnd Gundogan thinks they are a major threat.\\nHe said: \"Tottenham are a great team. They have the style of football. They have young English players. Our experience last season shows it is really tough to beat them.\\n\"They are really uncomfortable to play against.\\n\"I am pretty sure, even if they will not say it loud, the people who know the Premier League know Tottenham are definitely a competitor for the title.\"</td>\n",
              "      <td>Manchester City midfielder Ilkay Gundogan says it has been mentally tough to overcome a third major injury.</td>\n",
              "      <td>40758845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Work and Pensions Secretary Iain Duncan Smith said Labour - which is opposing the cap - was \"in denial\" over the state of the economy.\\nBut Labour argued the cap would be a \"hit and run\" on working families.\\nBenefits have historically risen in line with the rate of inflation. The Commons vote is due at 19:00 GMT.\\nThe House of Commons is debating the Welfare Benefits Uprating Bill, which would keep benefit rises to 1% for three years from next April.\\nThe coalition argues this is necessary to reduce the deficit, and is fair at a time when public sector pay is being capped and salaries in the private sector are rising below the rate of inflation.\\nBut Labour, which opposes the cap, says it will result in a real-terms cut in support for millions of working people.\\nSome Lib Dem MPs, including David Ward, John Leech, Julian Huppert and former minister Sarah Teather, are expected to rebel against the government while others - including Julian Huppert - could abstain.\\nMr Leech, MP for Manchester Withington, said he found it \"objectionable that the Tories are using 'skivers versus strivers' rhetoric to justify a cut to seven million working families\".\\nDespite the concerns of some Lib Dems, the coalition is thought likely to win the vote.\\nLegislation is needed to implement changes announced by Chancellor George Osborne in last month's Autumn Statement - to cap increases in jobseeker's allowance, employment and support allowance, income support and elements of housing benefit.\\nThe cap would also apply to maternity allowance, sick pay, maternity pay and paternity pay as well as the couple and lone parent elements of the working tax credit and the child element of the child tax credit.\\nThese benefits traditionally rise in line with consumer prices in an annual process known as \"uprating\".\\nBy Ross HawkinsPolitical correspondent, BBC News\\nGlance at the spreadsheets and the scale of the saving is apparent.\\nFigures in the Autumn Statement show raising many benefits and tax credits by 1% a year will save Â£2.8bn in 2015/16, compared with the government's previous plans.\\nThe overall welfare budget in 2011/12, as calculated by the Institute for Fiscal Studies, is Â£201bn.\\nThe political debate will centre on who should feel the pain.\\nJobseekers Allowance totals 2.4% of the total bill, according to the IFS. Benefits for those on low incomes make up just under 21%.\\nThose for elderly people, including the state pension, make up over 42%.\\nThe estimated value of fraud and error overpayments in benefit expenditure in 2011-12 is Â£3.2 billion.\\nThey increased 5.2% this year and without the planned change would have been set to rise by 2.2% - the rate of CPI inflation last September, on which the figure is calculated. The rate of inflation has since risen to 2.7%.\\nDuring lively scenes in Parliament, Mr Duncan Smith said: \"The number one priority now is reducing the deficit that they [Labour] left us - the biggest deficit since the Second World War.\"\\nHe added that the gap between the rate of income inflation between workers and the unemployed had \"grown\" in the last few years.\\n\"These are decisions that we are not taking easily but these are circumstances that they [Labour] are in denial about,\" Mr Duncan Smith said.\\nFor Labour, shadow work and pensions secretary Liam Byrne accused the government of presiding over an increase in unemployment.\\nBut Mr Duncan Smith said this was not the case and that the US and other European countries were faring worse than the UK.\\nMr Byrne said the government was showing \"contempt\" by trying to \"ram this bill through the House in just one day\".\\nHe added: \"It's turning into a hit-and-run on working families and we should not stand for it.\"\\nGreen Party MP Caroline Lucas said: \"Isn't the truth of this that it's a mean and miserable piece of legislation from a mean and miserable government?\"\\nSarah Teather, who was replaced as an education minister in last autumn's government reshuffle, said she would oppose the bill \"with a heavy heart\" because it was \"disingenuous\" to try to \"find someone to blame for our own woes\".\\n\"A fissure already exists between the working and non-working poor,\" she told MPs. \"Hammering on that fault line with the language of 'shirkers and strivers' will have long-term impacts on public attitudes, on attitudes of one neighbour against another.\\n\"It will make society less generous, less sympathetic, less able to co-operate.\"\\nHowever, Lib Dem deputy leader Simon Hughes told the House: \"It's difficult but the government has got the right and I believe, after this parliament, it will be vindicated by getting more people in work and fewer out of work.\"\\nDavid Cameron's official spokesman said: \"The prime minister's view is that the welfare system has to be brought back under control. The measures that the government has been taking, ever since the government came to power, have been designed to that end.\"\\nThe BBC's political correspondent Gary O'Donoghue said an \"impact assessment\" published by the government suggested single parents would be most affected by the cap - losing Â£5 a week or about Â£250 over the three year period.\\nThe majority of working age households in receipt of state support are likely be an average of Â£3 a week worse off.</td>\n",
              "      <td>The government has urged MPs to back a 1% cap on annual rises in working-age benefits and some tax credits, arguing it is vital to cutting the deficit.</td>\n",
              "      <td>20936833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input and output sequences\n",
        "def batch_tokenize_preprocess(batch, tokenizer):\n",
        "    source, target = batch[\"document\"], batch[\"summary\"]\n",
        "        \n",
        "    source_tokenized = tokenizer(\n",
        "        source, truncation=True\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, truncation=True\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch"
      ],
      "metadata": {
        "id": "ckuytzLUk8nX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"summary\"],\n",
        "        examples[\"document\"],\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\",\n",
        "    )"
      ],
      "metadata": {
        "id": "6hjlunk2k90z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the tokenization function to the dataset\n",
        "tokenized_dataset = raw_datasets.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets['train'].column_names\n",
        ")\n",
        "\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "f93eb527223f4970a7dc5bfe5aa12289",
            "827ef72aeda74498875ad3c876bee7db",
            "6cb15f3a68004205855a3106e4c51367",
            "c1509e9e47e94257a00c2e833ea7da20",
            "d3ba93daeb384d0dbecf00829ea95d05",
            "2f250d7e114a4b5e8c3090afd269af1f",
            "a85556e244824f96bc1f79a98ddb2453",
            "ba54680dbe1f4a7896640de654931a4a",
            "a2b7e86e51a74717bc6f0c6a3d4b754e",
            "bb456a282d934b729d4f6c024fc4a95d",
            "344fb5e6ef7e4b1484cdd3d2ff536580",
            "47cab4ed1faf49dc846da6fdacdc012a",
            "58833013367c4674afa21c77bdb3f189",
            "7b1865d2caf84bb0bfd557ab1a366390",
            "17b7be62b0c24bc1b127cda8f07e6754",
            "ca43edcaa59e434eb4597fcf475d3dbe",
            "3efc66015b1f418b929bf028a318de2c",
            "0a4e5d820b2d475d9fc986b2f0dca008",
            "750ef68192624c02aaa7a5f52be88aea",
            "40840bc04f574e729688bbd9c8c9f895",
            "aa027c7fccc744c3904997d2d37a763e",
            "cd33a8c68f3a4edf9a603567a7f66a50"
          ]
        },
        "id": "ONB_TDl1k_6r",
        "outputId": "be522c43-0420-4b5e-b4be-629c69ff8d5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f93eb527223f4970a7dc5bfe5aa12289"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47cab4ed1faf49dc846da6fdacdc012a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 90\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\", quiet=True)\n",
        "metric = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "AJGhZUNBlBIM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "id": "aUbgW3hulE5l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract a few results from ROUGE\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "id": "-QDb-SwZlGDE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNYJ8kQNlNW4",
        "outputId": "6fb00f3e-9fd1-4344-fd3b-eb81ba29c951"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MvpForConditionalGeneration(\n",
              "  (model): MvpModel(\n",
              "    (shared): Embedding(50267, 1024, padding_idx=1)\n",
              "    (encoder): MvpEncoder(\n",
              "      (embed_tokens): Embedding(50267, 1024, padding_idx=1)\n",
              "      (embed_positions): MvpLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x MvpEncoderLayer(\n",
              "          (self_attn): MvpAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (self_attn_prompt): MvpPrompt(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (prompt_embedding): Embedding(100, 1024)\n",
              "        (prompt_trans): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=800, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=800, out_features=24576, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): MvpDecoder(\n",
              "      (embed_tokens): Embedding(50267, 1024, padding_idx=1)\n",
              "      (embed_positions): MvpLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x MvpDecoderLayer(\n",
              "          (self_attn): MvpAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MvpAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (self_attn_prompt): MvpPrompt(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (prompt_embedding): Embedding(100, 1024)\n",
              "        (prompt_trans): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=800, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=800, out_features=24576, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (cross_attn_prompt): MvpPrompt(\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (prompt_embedding): Embedding(100, 1024)\n",
              "        (prompt_trans): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=800, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=800, out_features=24576, bias=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50267, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1 # Updated batch size\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"res\",\n",
        "    num_train_epochs=10, # Updated number of training epochs\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2, # Updated gradient accumulation steps\n",
        "    warmup_steps=100, # Updated warmup steps\n",
        "    weight_decay=0.1,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=100, # Updated evaluation steps\n",
        "    label_smoothing_factor=0.2, # Updated label smoothing factor\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=100,\n",
        "    save_total_limit=3, # Updated save total limit\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    # compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "2WZay2hHlXzT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_output = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "vuEcVt39liz1",
        "outputId": "92da42b1-5b1e-4fb9-fdd6-1c3ad8dc1d10"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a MvpTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [450/450 05:39, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.695500</td>\n",
              "      <td>4.805903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>3.623600</td>\n",
              "      <td>4.808611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>3.159100</td>\n",
              "      <td>4.802355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.981700</td>\n",
              "      <td>4.789385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_evaluate = trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "XikduFyVl-qZ",
        "outputId": "2875c7b2-f577-4658-a891-af83ccde6113"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_story(prompt, model, tokenizer, max_length=512, num_return_sequences=5):\n",
        "    inputs = tokenizer(prompt, truncation=True, return_tensors=\"pt\")\n",
        "    device = model.device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=max_length,\n",
        "        num_beams=6,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "    )\n",
        "\n",
        "    generated_stories = []\n",
        "    for output in outputs:\n",
        "        generated_story = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        generated_stories.append(generated_story)\n",
        "\n",
        "    return \"\\n\".join(generated_stories)"
      ],
      "metadata": {
        "id": "g2Wj_VOw8fXE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"My mother is a person I admire most. She devoted a lot of time and energy to the upbringing of my two brothers and 1. Despite working hard, she always made time to teach us many useful things which are necessary and important in our later lives. Moreover, she is a good role model for me to follow. She always tries to get on well with people who live next door and help everyone when they are in difficulties, so most of them respect and love her. I admire and look up to my mother because she not only brings me up well but also stands by me and gives some help if necessary. For example, when I encounter some difficulties, she will give me some precious advice to help me solve those problems. She has a major influence on me and 1 hope that I will inherit some of her traits.\"\n",
        "stories = summarize_story(prompt, model, tokenizer, num_return_sequences=5)\n",
        "print(stories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH5i3y548ieM",
        "outputId": "b3c7dae2-81b7-42d8-b629-32eb9b6a87d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My mother has a major influence on me and I hope that I will inherit some of her traits.\n",
            "My mother has a major influence on me and I hope I will inherit some of her traits.\n",
            "My mother has a major influence on me and I hope to inherit some of her traits.\n",
            "My mother has a major influence on me.\n",
            "My mother has been a role model for me.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"There are five members in my family. They are my father, my mother, my two younger sisters, and me. My father is a doctor. He is tall and kind. He likes playing football very much. He teaches me to play football every day after school. My mother is a housewife. She is short and thin. She cooks so well that everyone in the family loves her food very much. She teaches me how to cook delicious food too. I have two younger sisters - Lan and Hoa. Lan is 12 years old and Hoa is 10 years old. They are good students at school. I love my family.\"\n",
        "stories = summarize_story(prompt, model, tokenizer, num_return_sequences=5)\n",
        "print(stories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMNQTDDC89Un",
        "outputId": "0b344e07-30b4-4220-c53c-54179b7693e6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love my family.\n",
            "I love my family very much.\n",
            "I have a family of five.\n",
            "I have a family that loves football very much.\n",
            "I have a family of 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Amidst the immense mountains and forests of Lam Dong province, Dalat, a beautiful town, captivates all those who have been there once. I am one of those. Dalat is often called the City of Eternal Spring. Flowers of all colors, with many species, the most numerous of which are orchids. More than anywhere else in Viet- nam, Dalat sees flowers vie with one another in blos soming in spring. I used to get up early in the morn- ing on fine days to welcome dawn on the highlands. Opening the windows, I had a breath-taking view of nature, and enjoyed the fragrance of wild flowers car- ried by the clouds, I felt relieved in my heart. In the late afternoons, I often reserved for visits to the Valley of Love and Sigh Lake covered with quiet pine forests. Twilight on Dalat also brought many pictures and sen- sations. The wind rustling through the pine forests, the roar of waterfalls, the chirping of birds and the clatter of horse â€˜s hoovesâ€¦.all of these unforgettable memories always remain with me.\"\n",
        "stories = summarize_story(prompt, model, tokenizer, num_return_sequences=5)\n",
        "print(stories)"
      ],
      "metadata": {
        "id": "_ZHVoSyT9GPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93382e3-3caa-4fd0-938e-48f7aba983e4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is a lot of talk that Dalat is the City of Eternal Spring, but I cannot understand why they would call it that.\n",
            "There is a lot of talk that Dalat is the city of Eternal Spring, but I cannot understand why they would call it that.\n",
            "There is a lot of talk that Dalat is the City of Eternal Spring, but I cannot understand why they would even contemplate leaving it.\n",
            "There is a lot of talk that Dalat is the City of Eternal Spring, but I cannot understand why they would even contemplate moving it.\n",
            "There is a lot of talk that Dalat is the City of Eternal Spring.\n"
          ]
        }
      ]
    }
  ]
}