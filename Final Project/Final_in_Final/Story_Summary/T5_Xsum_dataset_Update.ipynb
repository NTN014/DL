{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf7732cca7a040898318f5e8141a0649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b189ff7ec264950bbef27b9dfa7e2e5",
              "IPY_MODEL_5edc63fa5df4486eab5408ac3e103a5f",
              "IPY_MODEL_c29b08d4699b4925907faabe5d1a1754"
            ],
            "layout": "IPY_MODEL_292df169b546443896fde499c26d1dcf"
          }
        },
        "2b189ff7ec264950bbef27b9dfa7e2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4619c27a7c294e28858bce7bc3f755db",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5fc7990ce3da448eb11bb6c0a318c29e",
            "value": "Map: 100%"
          }
        },
        "5edc63fa5df4486eab5408ac3e103a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1de4db2950954d56a3d4691b51e19cd2",
            "max": 90000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7b655d5631242fc807bd104a8fb7455",
            "value": 90000
          }
        },
        "c29b08d4699b4925907faabe5d1a1754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c1ed0d5733049d192ef0cee3539ad0b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c69de4724dbf4729bb244170ae6233c4",
            "value": " 90000/90000 [02:43&lt;00:00, 647.22 examples/s]"
          }
        },
        "292df169b546443896fde499c26d1dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "4619c27a7c294e28858bce7bc3f755db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fc7990ce3da448eb11bb6c0a318c29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1de4db2950954d56a3d4691b51e19cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7b655d5631242fc807bd104a8fb7455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c1ed0d5733049d192ef0cee3539ad0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69de4724dbf4729bb244170ae6233c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f863695e3d74e159fcdd78cade8f4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c377cd5fa124457a8d2c68e54cdf22a",
              "IPY_MODEL_2e192d99c0fe49bdad7ba7836087ac15",
              "IPY_MODEL_885f6872bee34e909bbfdb5586d65647"
            ],
            "layout": "IPY_MODEL_6dfe42a5e6d24c94be189f12960a976c"
          }
        },
        "6c377cd5fa124457a8d2c68e54cdf22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa67f57ffba64f79bc95adc62e2a8fc0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0845ace65ab349258906031aa6fc64df",
            "value": "Map: 100%"
          }
        },
        "2e192d99c0fe49bdad7ba7836087ac15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f64d7f2cb046c2b31e68ad2e8f30c9",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e00bbc7e47640c3b44b094263fdb61d",
            "value": 10000
          }
        },
        "885f6872bee34e909bbfdb5586d65647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8144e2dad6f94da2a1f18b8b2f488416",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_bfd6d94dbef547cbb0eeb06e3bf52a1e",
            "value": " 10000/10000 [00:16&lt;00:00, 668.46 examples/s]"
          }
        },
        "6dfe42a5e6d24c94be189f12960a976c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fa67f57ffba64f79bc95adc62e2a8fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0845ace65ab349258906031aa6fc64df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92f64d7f2cb046c2b31e68ad2e8f30c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e00bbc7e47640c3b44b094263fdb61d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8144e2dad6f94da2a1f18b8b2f488416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfd6d94dbef547cbb0eeb06e3bf52a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiNIXwQVkYJT",
        "outputId": "ca70a0f5-8a7b-4048-a376-1e00060e2142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets -qq\n",
        "!pip install transformers -qq\n",
        "!pip install rouge_score evaluate nltk -qq\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")"
      ],
      "metadata": {
        "id": "38bV9bfCkg2M"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import datasets\n",
        "import evaluate\n",
        "import nltk\n",
        "import torch\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "3-GPcSgQkoWH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "S3bbM8dekpgF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"t5-small\"\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "Gt-xBDgekqwI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "metric = load_metric(\"rouge\")\n",
        "\n",
        "# Load the XSum dataset\n",
        "raw_datasets = load_dataset('xsum', split=\"train[:100000]\")\n",
        "raw_datasets = raw_datasets.train_test_split(test_size=0.1)\n",
        "raw_datasets\n",
        "raw_datasets[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgK0QDdDkxUj",
        "outputId": "92285ef7-c8e6-458b-8eea-6f41f7f8953f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-bd04e72d51b7>:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"rouge\")\n",
            "WARNING:datasets.builder:Found cached dataset xsum (/root/.cache/huggingface/datasets/xsum/default/1.2.0/082863bf4754ee058a5b6f6525d0cb2b18eadb62c7b370b095d1364050a52b71)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'document': 'Bus company directors, cycling representatives and business leaders are among those taking part.\\nThe group will create a \"city centre movement strategy\" and set new targets on predicted journey times.\\n\"Nothing is off the table\" said mayor Marvin Rees. \"A quick fix is not the answer...I want a transport solution and so do the people of Bristol.\"\\nThe first meeting of the task group will take place on Tuesday.\\nTraffic jams have long been a problem in Bristol and various schemes have tried to fix the problem over the years.\\nIn 2003, a planned tram system was shelved amid disagreements between two councils, Bristol and South Gloucestershire.\\nA railway loop connecting Filton with Avonmouth was also dropped in 2015 in favour of a railway spur line instead.\\nWork is continuing on a bus rapid transport system, called Metrobus, with services starting in Autumn 2017.\\nThe next major roadwork scheme - to remove the gyratory system at Temple Gate, next to Temple Meads railway station - begins shortly.\\nOn BBC Points West\\'s Facebook page, a variety of suggestions to improve traffic flow have been put forward.\\nLiz Read suggested a congestion charge similar to London, while Dan White wrote \"build a time machine, go back to 2001 and make sure that the trams were built.\"',\n",
              " 'summary': 'The mayor of Bristol has vowed to improve traffic flow in the city with a new congestion task group.',\n",
              " 'id': '40258639'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_random_elements(dataset, num_examples=5):\n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, datasets.ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "sH8viw9Mkyup"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_random_elements(raw_datasets[\"train\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ax4dTW7Okz8a",
        "outputId": "0af7c041-d655-45c4-f227-caf6a96197dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>summary</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bridgend council wants to limit kerbside rubbish collections to save money and hit Welsh government targets.\\nThere are currently no restrictions on the number of black bags each household can put out.\\nA council spokeswoman said it was exploring use of different colour bags to show if the rules had been broken.\\nThe changes, which will also include the start of a nappy and sanitary item disposal service, will be introduced in April 2017.\\nCouncillors will discuss the changes during a meeting of the cabinet on Tuesday when the new seven year contract for waste collection will be awarded.\\nA report by the council in March said it was predicted to fall short of the Welsh government 58% target for recycling - meaning it could be fined at Ã‚Â£200 per tonne.\\nThe two bag restriction would mean it reaches 64% by 2019-2020, it predicted.\\nUnder the new system the council may issue a roll of specifically branded bags to each household, at the cost of about Ã‚Â£147,300 a year.\\nResidents who break the rules could have their waste left at the kerbside, their addresses could be recorded and they may be visited at home.</td>\n",
              "      <td>Residents in Bridgend county borough will only be able to throw away two black bin bags of household rubbish a fortnight under council changes.</td>\n",
              "      <td>37826992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dame Lowell Goddard, who resigned last month, said in a memo to MPs that the inquiry needed overhauling.\\nShe said the inquiry should focus less on the past and more on current standards of child protection.\\nNew chairwoman Alexis Jay said its terms of reference would remain but an internal review of it would be held.\\nLast month, Dame Lowell became the third chief to quit the Independent Inquiry into Child Sexual Abuse (IICSA), which was set up to investigate allegations made against local authorities, religious organisations, the armed forces and public and private institutions in England and Wales, as well as people in the public eye.\\nThe inquiry was set up after a string of scandals involving celebrities such as BBC DJ Jimmy Savile, who since his death in 2011 has been exposed as one of the UK's most prolific sexual predators, and the targeting of vulnerable children by organised gangs in towns such as Rotherham, Oxford and Rochdale.\\nThe spotlight also fell on sexual assaults carried out in schools, children's homes and at NHS sites.\\nThe inquiry was then launched in 2014 and it has announced 13 initial investigations, which include inquiries into the allegations of abuse by people of prominence.\\nIn her memo to the Home Affairs Select Committee, Dame Lowell said she had stepped down in order to challenge the way the probe was running.\\nThere was \"an inherent problem in the sheer scale and size of the inquiry\", she said - adding that its budget did not match.\\n\"Its boundless compass, including, as it does, every state and non-state institution, as well as relevant institutional contexts, coupled with the absence of any built-in time parameters, does not fit comfortably or practically within the single inquiry model.\"\\nShe said there should be a complete review, \"with a view to remodelling it and recalibrating its emphasis more towards current events and thus focusing major attention on the present and future protection of children\".\\nDame Lowell also said:\\nInquiry sources have told the BBC she lost the confidence of senior insiders.\\nHowever, Prof Jay said the panel would not be seeking any revision of the inquiry's terms of reference or introducing any new restrictions on its scope.\\n\"To ensure that the inquiry can meet the challenges it faces, I have already initiated a wide-ranging internal review of the inquiry's ways of working,\" she said.\\n\"We are currently looking at different approaches to evaluating the information we receive.\"\\nBut Lord Macdonald of River Glaven QC, who was director of public prosecutions from 2003 to 2008, said the probe's \"overwhelming focus on the past\" was \"ballooning out of control\" and called for its terms of reference to be rewritten.\\nPeter Saunders, founder of the charity National Association for People Abused in Childhood and a member of the victims' advisory panel for the inquiry, said it remained the \"best hope\" despite its scale.\\nThe prime minister's official spokeswoman said the government believed the inquiry was \"absolutely vital and we remain committed to doing it\".\\nA spokeswoman for the Home Office said: \"We owe it to victims and survivors to confront the appalling reality of how children were let down by the very people who were charged to protect them and to learn from the mistakes of the past.\"\\n7 July 2014 - government announces independent inquiry into the way public bodies investigated and handled child sex abuse claims. Baroness Butler-Sloss chosen as head\\n9 July - Baroness Butler-Sloss faces calls to quit because her late brother, Sir Michael Havers, was attorney general in the 1980s at the time of the alleged paedophile scandal. MPs and victims claimed she was too close to the establishment.\\n14 July - she stands down, saying she is \"not the right person\" for the job\\n5 September - Lord Mayor of London Fiona Woolf named the new head of the inquiry\\n11 October - Mrs Woolf discloses she had five dinners with Lord Brittan from 2008-12. The former home secretary faced questions over his handling of child abuse allegations during his time in office in the 1980s. Before his death in January 2015, Lord Brittan insisted proper procedures had been followed\\n22 October - abuse victim launches legal challenge against Mrs Woolf leading the inquiry, amid growing calls for her resignation\\n31 October - victims' groups tell government officials they are \"unanimous\" Mrs Woolf should quit. She steps down later that day\\n4 February 2015 - Justice Lowell Goddard, a serving judge of the High Court of New Zealand, announced as the new head of the inquiry\\nNovember - inquiry begins hearing directly from victims and survivors\\n4 August 2016 - Dame Lowell writes to Home Secretary Amber Rudd to resign from her post\\n11 August 2016 - Prof Alexis Jay announced as new head of the inquiry</td>\n",
              "      <td>The independent inquiry into child sex abuse is too big, bureaucratic and lacking in adequate systems, its former chairwoman has said.</td>\n",
              "      <td>37287620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Independent Financial Review Panel (IFRP) left their post last June when their appointments expired.\\nIn law it still exists, though the posts are vacant.\\nMembers of the independent body have now written to Northern Ireland Secretary James Brokenshire about MLAs' pay.\\nPat McCartan, Alan McQuillan, and Etta Campbell said they understand the reason they have not been replaced is because Sinn FÃ©in and the DUP are unable to agree a new system for overseeing expenses and pay.\\nIn their letter, they told Mr Brokenshire: \"Given our work and the general public disquiet expressed to the IFRP in every public consultation the panel undertook, we must strongly suggest that payments to MLAs in the absence of a functioning assembly and executive would be publicly regarded as unjustifiable.\\n\"Also, that any future system for payments to MLAs needs strong and independent administration, supervision, and audit.\\n\"If the government is therefore forced to suspend the assembly by Order in Council we strongly recommend that you consider strictly limiting the period for which members may draw salaries and expenses - perhaps to a period of three months to allow completion of any negotiations.\\n\"We do not even see why expenses should be paid for this period as these are supposed to relate to the management of MLAs' constituency offices and without a functioning assembly the work that can be done in these is very limited.\"\\nMr Brokenshire has said the primary responsibility lies with the Democratic Unionist Party (DUP) and Sinn FÃ©in to use the \"limited window\" now open to form a new power-sharing executive.\\nIt follows Thursday's election which ended a unionist majority at Stormont.\\nThe parties have just three weeks to overcome their differences and form an executive.\\nIf a government cannot be formed within that time then, under law, another election could be called.\\nUltimately, if no power-sharing government is formed, power could return to the UK Parliament at Westminster for the first time in a decade.</td>\n",
              "      <td>All payments to MLAs should be limited to a three-month period if direct rule becomes necessary, according to a body that used to set their pay.</td>\n",
              "      <td>39178754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The blast comes a day after 17 people died in another suicide attack at the central station in the city.\\nSecurity has been tightened at railway stations and airports across Russia.\\nMoscow is concerned that militants could be ramping up violence in the run-up to the 2014 winter Olympic Games in the city of Sochi in February.\\nThe Olympics venue is close to Russia's volatile north Caucasus region, and the BBC's Moscow correspondent Daniel Sandford says it was always risky staging the Games so near to the troubled republics of Chechnya and Dagestan.\\nBy Artyom LissBBC Russian\\nFor most Russians, these attacks came as a huge shock. Despite public assurances that the troubles in the Caucasus were coming under control, clashes between extremists and government troops, and some small-scale attacks, have continued.\\nMore disturbingly, extremism has recently started to flare up further north, in some of Russia's central regions, much closer to Volgograd.\\nThis industrial and transport hub is of huge symbolic importance to most Russians. The attacks there, just weeks before the opening of the Winter Olympics, have created unease across Russia. Many are now asking why the country's powerful security services failed to stop the bombers, accusing them of complacency and unprofessionalism.\\nThe threat to the games in Sochi may not be so great: there are hundreds of police officers and military personnel deployed around the area. But the fear is that the bombers may strike elsewhere.\\nThese bombs have been a brutal reminder of that, he says.\\nIn a statement, Russia's foreign ministry did not blame any particular group but called for international solidarity in the fight against \"an insidious enemy that can only be defeated together\".\\nRegional Governor Sergei Bozhenov said the bombings were a \"serious test\" for all Volgograd residents and all Russians.\\nThe president of the International Olympic Committee has expressed full confidence that Russian authorities will deliver \"safe and secure\" Games in Sochi.\\nThe latest explosion took place near a busy market in Volgograd's Dzerzhinsky district.\\nMaksim Akhmetov, a Russian TV reporter who was at the scene of the blast, said the trolleybus was packed with people going to work in the morning rush hour.\\nHe described the scene as \"terrible\", adding that the bus was \"ravaged\" and that there were \"bodies everywhere, blood on the snow\".\\nThe figures given for the number of dead and injured are still fluctuating, but investigators and the Russian health ministry told a news conference that 14 people had been killed.\\nAt least 20 others were injured, and Health Minister Veronika Skvortsova said the patients were in \"a bad condition with burns, with multiple injuries typical of blast-induced wounds\".\\nShe said the injured include a pregnant woman, two 16 year olds and a baby aged about six months whose parents are assumed dead.\\nThe regional governor has announced five days of mourning for all the victims.\\nThe force of the explosion removed much of the bus's exterior and broke windows in nearby buildings.\\n\"It is now possible to preliminarily say that the explosive device was set off by a suicide bomber - a man whose body fragments have been collected and sent for genetic testing,\" the Investigative Committee said in a statement.\\nCommittee spokesman Vladimir Markin said identical explosives were used in the two bombings, suggesting they were linked.\\nIn response to this second blast in less than 24 hours, Russian President Vladimir Putin has ordered security measures to be tightened across Russia and in particular in Volgograd.\\nLocal resident Polina Goncharova said the whole city was in shock.\\n\"This is the first time in my life that I have experienced anything like this. I have been crying since I heard about the first bombing, and now the second one today,\" she told the BBC.\\n\"There are very few people on the streets. I am staying at home myself as I'm worried there will be more attacks.\"\\nThe first blast rocked Volgograd-1 station at around 12:45 (08:45 GMT) on Sunday, at a time of year when millions of Russians are travelling to celebrate the New Year.\\nNo group has yet said it was behind the blast.\\nVolgograd was also targeted in October, when a suspected female suicide bomber killed six people in an attack on a bus.\\nAn Islamist insurgency in the North Caucasus region has led to many attacks there in recent years.\\nInsurgents have also attacked major Russian towns.\\nVolgograd lies about 900km (560 miles) south of Moscow, 650km north of the North Caucasus and 700km north-east of Sochi.</td>\n",
              "      <td>At least 14 people have been killed in a suicide bombing on a trolleybus in the Russian city of Volgograd, investigators say.</td>\n",
              "      <td>25546477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The 27-year-old has been with the Rams for three years, but did not feature for the Championship side last season.\\nLegzdins, who began his career as a trainee at Birmingham and has had spells at Crewe and Burton, has signed a two-year deal with the O's.\\nOrient boss Russell Slade had been looking for a senior keeper after Jamie Jones joined Preston last week.\\nLegzdins made 37 appearances in total during his three-year spell with Derby, but is now hoping to establish himself in east London.\\n\"I spoke to the manager and the goalkeeper coach and it became very clear the ambition of the club is to build on last year,\" Legzdins told the club website.\\n\"It was important for me to join a team where I would play and I wanted one that would be challenging at the right end of the table\\n\"Last year was disappointing for me for various reasons and I played fewer games than I'd hoped but the year before I played 33 games in the Championship.\\n\"That's my ambition; to play games. I don't want to be number two goalkeeper.\"</td>\n",
              "      <td>League One Leyton Orient have signed Derby County goalkeeper Adam Legzdins on a free transfer.</td>\n",
              "      <td>27835791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the input and output sequences\n",
        "def batch_tokenize_preprocess(batch, tokenizer):\n",
        "    source, target = batch[\"document\"], batch[\"summary\"]\n",
        "        \n",
        "    source_tokenized = tokenizer(\n",
        "        source, truncation=True\n",
        "    )\n",
        "    target_tokenized = tokenizer(\n",
        "        target, truncation=True\n",
        "    )\n",
        "\n",
        "    batch = {k: v for k, v in source_tokenized.items()}\n",
        "    # Ignore padding in the loss\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
        "        for l in target_tokenized[\"input_ids\"]\n",
        "    ]\n",
        "    return batch"
      ],
      "metadata": {
        "id": "ckuytzLUk8nX"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"summary\"],\n",
        "        examples[\"document\"],\n",
        "        truncation=True,\n",
        "        max_length=1024,\n",
        "        padding=\"max_length\",\n",
        "        return_tensors=\"pt\",\n",
        "    )"
      ],
      "metadata": {
        "id": "6hjlunk2k90z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the tokenization function to the dataset\n",
        "tokenized_dataset = raw_datasets.map(\n",
        "    lambda batch: batch_tokenize_preprocess(\n",
        "        batch, tokenizer\n",
        "    ),\n",
        "    batched=True,\n",
        "    remove_columns=raw_datasets['train'].column_names\n",
        ")\n",
        "\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "cf7732cca7a040898318f5e8141a0649",
            "2b189ff7ec264950bbef27b9dfa7e2e5",
            "5edc63fa5df4486eab5408ac3e103a5f",
            "c29b08d4699b4925907faabe5d1a1754",
            "292df169b546443896fde499c26d1dcf",
            "4619c27a7c294e28858bce7bc3f755db",
            "5fc7990ce3da448eb11bb6c0a318c29e",
            "1de4db2950954d56a3d4691b51e19cd2",
            "f7b655d5631242fc807bd104a8fb7455",
            "8c1ed0d5733049d192ef0cee3539ad0b",
            "c69de4724dbf4729bb244170ae6233c4",
            "3f863695e3d74e159fcdd78cade8f4f9",
            "6c377cd5fa124457a8d2c68e54cdf22a",
            "2e192d99c0fe49bdad7ba7836087ac15",
            "885f6872bee34e909bbfdb5586d65647",
            "6dfe42a5e6d24c94be189f12960a976c",
            "fa67f57ffba64f79bc95adc62e2a8fc0",
            "0845ace65ab349258906031aa6fc64df",
            "92f64d7f2cb046c2b31e68ad2e8f30c9",
            "1e00bbc7e47640c3b44b094263fdb61d",
            "8144e2dad6f94da2a1f18b8b2f488416",
            "bfd6d94dbef547cbb0eeb06e3bf52a1e"
          ]
        },
        "id": "ONB_TDl1k_6r",
        "outputId": "13e85171-8fe3-41e5-d99f-590fde813db1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/90000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf7732cca7a040898318f5e8141a0649"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f863695e3d74e159fcdd78cade8f4f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 90000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\", quiet=True)\n",
        "metric = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "AJGhZUNBlBIM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels"
      ],
      "metadata": {
        "id": "aUbgW3hulE5l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(\n",
        "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
        "    )\n",
        "    # Extract a few results from ROUGE\n",
        "    result = {key: value * 100 for key, value in result.items()}\n",
        "\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result"
      ],
      "metadata": {
        "id": "-QDb-SwZlGDE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNYJ8kQNlNW4",
        "outputId": "961bf3de-e5ff-4505-f04c-7934005f1540"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 512)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 512)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 8)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-5): 5 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
              "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
              "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16 # Updated batch size\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"res\",\n",
        "    num_train_epochs=1, # Updated number of training epochs\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=2, # Updated gradient accumulation steps\n",
        "    warmup_steps=1000, # Updated warmup steps\n",
        "    weight_decay=0.1,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=1000, # Updated evaluation steps\n",
        "    label_smoothing_factor=0.2, # Updated label smoothing factor\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=500,\n",
        "    save_total_limit=3, # Updated save total limit\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "2WZay2hHlXzT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_output = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "vuEcVt39liz1",
        "outputId": "b7efe18b-6c60-4344-9475-dd14cbbeb62c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2812' max='2812' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2812/2812 1:02:00, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>5.335500</td>\n",
              "      <td>5.052552</td>\n",
              "      <td>26.009300</td>\n",
              "      <td>6.325500</td>\n",
              "      <td>20.306800</td>\n",
              "      <td>20.300400</td>\n",
              "      <td>18.723700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>5.162100</td>\n",
              "      <td>4.942667</td>\n",
              "      <td>27.356500</td>\n",
              "      <td>7.207100</td>\n",
              "      <td>21.473100</td>\n",
              "      <td>21.467600</td>\n",
              "      <td>18.786000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_evaluate = trainer.evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "XikduFyVl-qZ",
        "outputId": "91c22d20-0356-40b0-945e-c00a310dd133"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 05:30]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(prompt, model, tokenizer, max_length=512, num_return_sequences=3):\n",
        "    inputs = tokenizer(prompt, truncation=True, return_tensors=\"pt\")\n",
        "    device = model.device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=max_length,\n",
        "        num_beams=6,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "    )\n",
        "\n",
        "    generated_stories = []\n",
        "    for output in outputs:\n",
        "        generated_story = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        generated_stories.append(generated_story)\n",
        "\n",
        "    return generated_stories"
      ],
      "metadata": {
        "id": "7PbKg_sKl__X"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"My mother is a person I admire most. She devoted a lot of time and energy to the upbringing of my two brothers and 1. Despite working hard, she always made time to teach us many useful things which are necessary and important in our later lives. Moreover, she is a good role model for me to follow. She always tries to get on well with people who live next door and help everyone when they are in difficulties, so most of them respect and love her. I admire and look up to my mother because she not only brings me up well but also stands by me and gives some help if necessary. For example, when I encounter some difficulties, she will give me some precious advice to help me solve those problems. She has a major influence on me and 1 hope that I will inherit some of her traits.\"\n",
        "generated_story = generate_story(prompt, model, tokenizer, num_return_sequences=5)\n",
        "print(generated_story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSNX1j1GmCTv",
        "outputId": "5a512346-f175-4e13-d5c5-5b642535af40"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I admire and look up to my mother because she brings me up well and gives me some precious advice to help me solve those problems.', 'My mother is a person I admire most.', 'I admire and look up to my mother because she has a major influence on me.', 'I admire and look up to my mother because she brings me up well and gives me some precious advice to help me solve those difficulties.', 'I admire and look up to my mother because she brings me up well and gives me some valuable advice to help me solve those problems.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"My mother is a person I admire most. She devoted a lot of time and energy to the upbringing of my two brothers and 1. Despite working hard, she always made time to teach us many useful things which are necessary and important in our later lives. Moreover, she is a good role model for me to follow. She always tries to get on well with people who live next door and help everyone when they are in difficulties, so most of them respect and love her. I admire and look up to my mother because she not only brings me up well but also stands by me and gives some help if necessary. For example, when I encounter some difficulties, she will give me some precious advice to help me solve those problems. She has a major influence on me and 1 hope that I will inherit some of her traits.\"\n",
        "generated_story = generate_story(prompt, model, tokenizer)\n",
        "print(generated_story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-5_7Bk07pvu",
        "outputId": "dbfe8803-458b-4a29-ad8a-33ff4e1d6e06"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I admire and look up to my mother because she brings me up well and gives me some precious advice to help me solve those problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_story(prompt, model, tokenizer, max_length=512, num_return_sequences=5):\n",
        "    inputs = tokenizer(prompt, truncation=True, return_tensors=\"pt\")\n",
        "    device = model.device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    outputs = model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=max_length,\n",
        "        num_beams=6,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=2,\n",
        "        num_return_sequences=num_return_sequences,\n",
        "    )\n",
        "\n",
        "    generated_stories = []\n",
        "    for output in outputs:\n",
        "        generated_story = tokenizer.decode(output, skip_special_tokens=True)\n",
        "        generated_stories.append(generated_story)\n",
        "\n",
        "    return \"\\n\".join(generated_stories)"
      ],
      "metadata": {
        "id": "g2Wj_VOw8fXE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"My mother is a person I admire most. She devoted a lot of time and energy to the upbringing of my two brothers and 1. Despite working hard, she always made time to teach us many useful things which are necessary and important in our later lives. Moreover, she is a good role model for me to follow. She always tries to get on well with people who live next door and help everyone when they are in difficulties, so most of them respect and love her. I admire and look up to my mother because she not only brings me up well but also stands by me and gives some help if necessary. For example, when I encounter some difficulties, she will give me some precious advice to help me solve those problems. She has a major influence on me and 1 hope that I will inherit some of her traits.\"\n",
        "stories = summarize_story(prompt, model, tokenizer, num_return_sequences=5)\n",
        "print(stories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH5i3y548ieM",
        "outputId": "1005bb45-741c-4010-dc80-953a1c5154bf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I admire and look up to my mother because she brings me up well and gives me some precious advice to help me solve those problems.\n",
            "My mother is a person I admire most.\n",
            "I admire and look up to my mother because she has a major influence on me.\n",
            "I admire and look up to my mother because she brings me up well and gives me some precious advice to help me solve those difficulties.\n",
            "I admire and look up to my mother because she brings me up well and gives me some valuable advice to help me solve those problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"There are five members in my family. They are my father, my mother, my two younger sisters, and me. My father is a doctor. He is tall and kind. He likes playing football very much. He teaches me to play football every day after school. My mother is a housewife. She is short and thin. She cooks so well that everyone in the family loves her food very much. She teaches me how to cook delicious food too. I have two younger sisters - Lan and Hoa. Lan is 12 years old and Hoa is 10 years old. They are good students at school. I love my family.\"\n",
        "stories = summarize_story(prompt, model, tokenizer, num_return_sequences=5)\n",
        "print(stories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMNQTDDC89Un",
        "outputId": "f2840154-837f-436b-f4b5-3fd648370277"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My father is a doctor.\n",
            "My mother is a housewife.\n",
            "My father, my mother and two younger sisters are members of my family.\n",
            "My mother is a doctor.\n",
            "My father, my mother, and my two younger sisters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZHVoSyT9GPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}