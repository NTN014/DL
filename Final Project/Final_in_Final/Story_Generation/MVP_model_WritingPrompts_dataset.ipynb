{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-AWi0lxwe9n"
      },
      "source": [
        "#1. Prepare some packages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcuKL0rvwoYE"
      },
      "source": [
        "#1.1 Install packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw06s-g7m0-a",
        "outputId": "1f4b3df4-8f88-4ac8-bbb4-43eb200f5394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tue May 16 11:06:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oJ8iH6woNVq"
      },
      "outputs": [],
      "source": [
        "!pip install datasets -qq\n",
        "!pip install transformers -qq\n",
        "!pip install evaluate nltk rouge_score -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUtit1GQoZGU",
        "outputId": "304e14ea-6c77-459b-d33d-3270688e8d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yf7UYAeoWGn",
        "outputId": "662b618a-402e-447e-c561-da6fee005121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-vsei99q_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-vsei99q_\n",
            "  Resolved https://github.com/huggingface/accelerate to commit dcde1e93d09abea02a8e7f4a07a2c5734b87b60e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.20.0.dev0) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.20.0.dev0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.0.dev0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.20.0.dev0) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.20.0.dev0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.20.0.dev0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTuuNJ-GoU4L",
        "outputId": "0a5c56a2-189a-491c-d036-056d1d35db92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.20.0.dev0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJs_ldk4vsaU"
      },
      "source": [
        "#1.2 Import libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KamXPuIobPp"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "import evaluate\n",
        "import nltk\n",
        "import torch\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "from nltk.tokenize import word_tokenize\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJF9ku8ZyczU"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEuCMYYEokPP"
      },
      "outputs": [],
      "source": [
        "from transformers import MvpForConditionalGeneration, MvpTokenizerFast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlfA4KMBznh8"
      },
      "outputs": [],
      "source": [
        "from transformers.optimization import AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSPJQz3QvvsR"
      },
      "source": [
        "# 2. Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S02V5y_Rv2h1"
      },
      "source": [
        "#2.1 Read file and do a little text clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgQj0Yx_opRD"
      },
      "outputs": [],
      "source": [
        "#do a littel text clean with punctuations\n",
        "def cleanpunctuation(s):\n",
        "    for p in '!,.:;?':\n",
        "        s=s.replace(' '+p,p)\n",
        "    s=s.replace(' '+'n\\'t','n\\'t')\n",
        "    s=s.replace(' '+'\\'s','\\'s')\n",
        "    s=s.replace(' '+'\\'re','\\'re')\n",
        "    s=s.replace(' '+'\\'ve','\\'ve')\n",
        "    s=s.replace(' '+'\\'ll','\\'ll')\n",
        "    s=s.replace(' '+'\\'am','\\'am')\n",
        "    s=s.replace(' '+'\\'m','\\'m')\n",
        "    s=s.replace(' '+'\\' m','\\'m')\n",
        "    s=s.replace(' '+'\\'m','\\'m')\n",
        "    s=s.replace(' '+'\\' ve','\\'ve')\n",
        "    s=s.replace(' '+'\\' s','\\'s')\n",
        "    s=s.replace('<newline>','\\n')\n",
        "    return s "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4FF5gAQt7Gp"
      },
      "outputs": [],
      "source": [
        "fTrain=open(os.path.join('valid.wp_combined'),encoding='utf8')\n",
        "fTest=open(os.path.join('test.wp_combined'),encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBQZLAknt809"
      },
      "outputs": [],
      "source": [
        "data_train=fTrain.readlines()\n",
        "data_test=fTest.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1w2Sh-no6KN",
        "outputId": "88c9031a-ebf7-4166-adab-e358b7fd262b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset length: 15620\n",
            "Test dataset length: 15138\n"
          ]
        }
      ],
      "source": [
        "print(\"Train dataset length: \"+str(len(data_train)))\n",
        "print(\"Test dataset length: \"+ str(len(data_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKiv_YCno9wG"
      },
      "outputs": [],
      "source": [
        "train_text=list(map(cleanpunctuation,data_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abZJ8SFXo-5n"
      },
      "outputs": [],
      "source": [
        "test_text=list(map(cleanpunctuation,data_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHt_oXDovZrh"
      },
      "outputs": [],
      "source": [
        "train_text = train_text[:5000]\n",
        "test_text = test_text[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "ctTtWXClpHHa",
        "outputId": "e2292657-461e-4767-aef5-1a03b1ff1e3d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"[ WP ] `` On your right, you'll see natives living along the beach, and they are NOT happy with us being in their sacred waters. '' <endprompts> `` On your right, you'll see the natives living along the beach, and they are NOT happy with us being in their sacred waters. '' Marcus muttered into an imaginary microphone as we floated on our shamble of a armored rubber raft, now riddled with darts and primitive arrows. \\n \\n The emergency escape pod suffered severe damage on the drop down to planet side. The light weight and heat resistant alloys made for makeshift armor for ourselves and our rubber survival raft. Our only hope was to get out of the territory of these natives and get to the Federation outpost downriver. \\n \\n The ape-like primitives were much akin to gorillas from earth in terms of survival habits. Building `` nests '' in trees, which were more like tree houses that any kid would want, and not being able to swim and just not liking water in general, getting most of their hydration from native plants and fruits. \\n \\n I was to be conducting studies of the primitives, to see if they were viable to learn, be educated, and introduced to the galactic stage. It was doubtful, as my 2 years spent observing them from the Federation Cruiser, the *Iaculum*, proved they they were essentially at their peak of civilization. My colleague had much less respect for said natives however, making constant jokes of giving the peace presents of bananas. \\n \\n The natives walked the shore, matching the pace of our boat in the current, some carrying spiked clubs made from the tails of some native fauna, some with blow guns, others with crude bows. The small\\n\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_text[9]      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNjyyQbkyXKw"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--seed', type=int, default=88888)\n",
        "parser.add_argument(\"--model_name\", default=\"gpt2\", type=str)\n",
        "parser.add_argument(\"--max_seq_length\", default=512, type=int)\n",
        "parser.add_argument(\"--train_batch_size\", default=4, type=int)\n",
        "parser.add_argument(\"--valid_batch_size\", default=4, type=int)\n",
        "parser.add_argument(\"--num_train_epochs\", default=1, type=int)\n",
        "parser.add_argument(\"--warmup\", default=0.1, type=float)\n",
        "parser.add_argument(\"--learning_rate\", default=5e-5, type=float)\n",
        "# parser.add_argument(\"--input_text_path\", default='../input/story-text', type=str)\n",
        "args, _ = parser.parse_known_args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zqM0oCVwPPO"
      },
      "source": [
        "#2.2 Tokenize and load to dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1M2MOgzwQqz"
      },
      "outputs": [],
      "source": [
        "tokenizer = MvpTokenizerFast.from_pretrained(\"RUCAIBox/mvp\")\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ee-ahlzfJe-O"
      },
      "outputs": [],
      "source": [
        "# Tokenize the stories\n",
        "def tokenize_stories(stories):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    for story in stories:\n",
        "        encoded_dict = tokenizer.encode_plus(story, \n",
        "                                              add_special_tokens=True, \n",
        "                                              max_length=512, \n",
        "                                              pad_to_max_length=True, \n",
        "                                              return_attention_mask=True, \n",
        "                                              return_tensors='tf')\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "    input_ids = tf.concat(input_ids, axis=0)\n",
        "    attention_masks = tf.concat(attention_masks, axis=0)\n",
        "    return input_ids, attention_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxJdMP0FKeU_",
        "outputId": "d0511cbe-63ae-4592-911c-daf3300ca7d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_input_ids, train_attention_masks = tokenize_stories(train_text)\n",
        "test_input_ids, test_attention_masks = tokenize_stories(test_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWpoiazQP-MC"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(train_input_ids))\n",
        "val_size = len(train_input_ids) - train_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vMRHoIcQQML"
      },
      "outputs": [],
      "source": [
        "train_input_ids, val_input_ids = tf.split(train_input_ids, [train_size, val_size])\n",
        "train_attention_masks, val_attention_masks = tf.split(train_attention_masks, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YvK5EA7QUC3"
      },
      "outputs": [],
      "source": [
        "# Prepare the training data\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_input_ids, train_attention_masks))\n",
        "train_data = train_data.shuffle(len(train_input_ids)).batch(8, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9glJsHlzQW9d"
      },
      "outputs": [],
      "source": [
        "# Prepare the validation data\n",
        "val_data = tf.data.Dataset.from_tensor_slices((val_input_ids, val_attention_masks))\n",
        "val_data = val_data.batch(8, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPTwmHY_QaA1"
      },
      "outputs": [],
      "source": [
        "# Define the training loop\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bub9olKzQcVh"
      },
      "outputs": [],
      "source": [
        "from transformers import TextDataset,DataCollatorForLanguageModeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaxLiqA8QlbR"
      },
      "outputs": [],
      "source": [
        "#file path\n",
        "train_path = '/content/valid.wp_combined'\n",
        "test_path = '/content/test.wp_combined'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHR9WiTIQd_2",
        "outputId": "2d573cef-52a1-4c41-eadd-c4b94d6fc5d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5893735 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "\n",
        "# def load_dataset(train_path,test_path,tokenizer):\n",
        "#     train_dataset = TextDataset(\n",
        "#           tokenizer=tokenizer,\n",
        "#           file_path=train_path,\n",
        "#           block_size=128)\n",
        "     \n",
        "#     test_dataset = TextDataset(\n",
        "#           tokenizer=tokenizer,\n",
        "#           file_path=test_path,\n",
        "#           block_size=128)   \n",
        "    \n",
        "#     data_collator = DataCollatorForLanguageModeling(\n",
        "#         tokenizer=tokenizer, mlm=False,\n",
        "#     )\n",
        "#     return train_dataset,test_dataset,data_collator\n",
        "\n",
        "# train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDTlds0gRHy0"
      },
      "outputs": [],
      "source": [
        "model = MvpForConditionalGeneration.from_pretrained(\"RUCAIBox/mvp-story\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btGvVIkbQtPA"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEXeiCA1Qx0K"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./mvp_out\",  # The output directory\n",
        "    overwrite_output_dir=True,  # Overwrite the content of the output directory\n",
        "    num_train_epochs=1,  # Number of training epochs\n",
        "    per_device_train_batch_size=8,  # Batch size for training\n",
        "    per_device_eval_batch_size=8,  # Batch size for evaluation\n",
        "    eval_steps=400,  # Number of update steps between two evaluations\n",
        "    save_steps=800,  # After how many steps the model is saved\n",
        "    warmup_steps=500,  # Number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "\n",
        "# Clear GPU memory cache before training\n",
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjPjjO5zQ1sN"
      },
      "outputs": [],
      "source": [
        "# Clear GPU memory cache before training\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q8hLrpAUVGP"
      },
      "outputs": [],
      "source": [
        "prompt=test_text[5][:test_text[300].find('<endprompts>')]\n",
        "target=test_text[5][test_text[300].find('<endprompts>')+5:]\n",
        "\n",
        "def generate_story(prompt,target,k=0,p=0.9,output_length=100,temperature=1,num_return_sequences=1,repetition_penalty=1.0):\n",
        "    print(\"====prompt====\\n\")\n",
        "    print(prompt+\"\\n\")\n",
        "    print('====target story is as below===\\n')\n",
        "    print(target+\"\\n\")\n",
        "    encoded_prompt = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
        "    model.to('cpu')\n",
        "    model.eval()\n",
        "    output_sequences = model.generate(\n",
        "        input_ids=encoded_prompt,\n",
        "        max_length=output_length,\n",
        "        temperature=temperature,\n",
        "        top_k=k,\n",
        "        top_p=p,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        do_sample=True,\n",
        "        num_return_sequences=num_return_sequences\n",
        "    )\n",
        "    if len(output_sequences.shape) > 2:\n",
        "        output_sequences.squeeze_()\n",
        "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
        "        print(\"=== GENERATED SEQUENCE {} ===\".format(generated_sequence_idx + 1))\n",
        "        generated_sequence = generated_sequence.tolist()\n",
        "        # Decode text\n",
        "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
        "        # Remove all text after eos token\n",
        "        # text = text[: text.find(tokenizer.eos_token)]\n",
        "        print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_McodGUU62w",
        "outputId": "7619fa76-d5ed-4404-ee18-65468f5af009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "====prompt====\n",
            "\n",
            "[ TT ] `` Shut the dog up. '' <endprompts> “ Shut the dog \n",
            "\n",
            "====target story is as below===\n",
            "\n",
            " shouted my head officer from the jeep. The dog was running circles around our vehicle, barking at the people inside. The officer tapped my shoulder and pointed to the yellow, skinny animal circling our jeep. \n",
            " \n",
            " “ But sir.., ” I managed to spit out before he took both his hands and pushed me out of the vehicle. I went tumbling out, and landed on the rough sandy ground. I stood up adjusting the gun hanging from my shoulder and proceeded to walk towards the canine. The dog stopped its barking, and shifted its black eyes to me. \n",
            " \n",
            " “ Come here little pup. Hey come here, I ’ m not going to hurt ya, ” I said trying to coax it nearer to me. Actually, I didn ’ t know if I was going to hurt the little mutt or not yet. Reaching my hand towards my waist, I pulled off a tiny bit of my rations. I held it out my hand, with the ration laying on my open palm. The dog perked it ’ s ears, and came a few inches closer to me. Ever so slightly the skittish animal moved its way closer to my hand. At first only a couple inches, then a foot closer, until finally its snout was centimeter from my hand. I could see the small flecks of sand coating its fur. I pushed the ration closer to its teeth. \n",
            " \n",
            " “ GRUNT, ” the sound of my officer ’ s voice rang out, scaring the dog away. A\n",
            "\n",
            "\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "</s><s> TT ] `` Shut the dog up. '' <endprompts> “ Shut the gun    '' TT [ TT ] '' TT ]'Shut the house up. TT ] *TT ] '' Shut the door up.TT ] `` shut the dog  TT ] ” TT ], TT ]. TT ] > TT ] TT ] \" Shut the dogs up. * TT ] ) TT ] ` Shut the girl up. It was a new line of the</s>\n"
          ]
        }
      ],
      "source": [
        "generate_story(prompt,target)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05e4534f68a948b5b8fb6bc972dbd617": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11bb8ac84d3c41578346958267098af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cfe960f02e346698476bf2d7fd1287e",
            "placeholder": "​",
            "style": "IPY_MODEL_a2e09cb3dd694727af19d093f0eee809",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "3139f5801d584ac19c705b0103a0aa95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3301bc28c5874690b2d9b094c7d5face": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cee09d6de24427190a336189d06e4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46792535d06c4ad8abe4c6596b9d63ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11bb8ac84d3c41578346958267098af2",
              "IPY_MODEL_73690b8257c74d3fb1bd5d0fb3d7cf1f",
              "IPY_MODEL_d1dda8f6075c4340ac4c9a93ddb0d3f8"
            ],
            "layout": "IPY_MODEL_05e4534f68a948b5b8fb6bc972dbd617"
          }
        },
        "53e8c78a28a94d5a9d463a74e2ec015d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b836f7f441784922909f28c1159cad6d",
              "IPY_MODEL_f8c119de2383406fb041273c9066c30c",
              "IPY_MODEL_8417e895f6d9458cba4a3ea4765a2ec9"
            ],
            "layout": "IPY_MODEL_f569ec7811424076906985abed7036eb"
          }
        },
        "5cfe960f02e346698476bf2d7fd1287e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e34c8180a0d43159eba29bd08b6b852": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73690b8257c74d3fb1bd5d0fb3d7cf1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa2c938ee35346aa97be16a489ad9128",
            "max": 1872844515,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a0a667330124313b27f6bd33fedf250",
            "value": 1872844515
          }
        },
        "8417e895f6d9458cba4a3ea4765a2ec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3139f5801d584ac19c705b0103a0aa95",
            "placeholder": "​",
            "style": "IPY_MODEL_8b9ae29a49534359a1119d2ebf551298",
            "value": " 956/956 [00:00&lt;00:00, 30.8kB/s]"
          }
        },
        "8a0a667330124313b27f6bd33fedf250": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8b560f16cb7b4b36b5f37c324ec8c4e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b9ae29a49534359a1119d2ebf551298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2e09cb3dd694727af19d093f0eee809": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b836f7f441784922909f28c1159cad6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e34c8180a0d43159eba29bd08b6b852",
            "placeholder": "​",
            "style": "IPY_MODEL_3301bc28c5874690b2d9b094c7d5face",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "c61b0f55ba0b4295a9457ea7f6af0cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1dda8f6075c4340ac4c9a93ddb0d3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb723a96e54c4240bc4743b7fa08db3c",
            "placeholder": "​",
            "style": "IPY_MODEL_c61b0f55ba0b4295a9457ea7f6af0cbb",
            "value": " 1.87G/1.87G [01:50&lt;00:00, 17.7MB/s]"
          }
        },
        "f569ec7811424076906985abed7036eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8c119de2383406fb041273c9066c30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b560f16cb7b4b36b5f37c324ec8c4e0",
            "max": 956,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cee09d6de24427190a336189d06e4ae",
            "value": 956
          }
        },
        "fa2c938ee35346aa97be16a489ad9128": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb723a96e54c4240bc4743b7fa08db3c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
