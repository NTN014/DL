{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d48e56ad4d6b4a119b2d55965cb7c872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cba8b623e034191ae413efc82bb5d77",
              "IPY_MODEL_a2a012e735ef460db24faedb1ea88da8",
              "IPY_MODEL_52f69431dd7c4202ae6d0a9170e89f53"
            ],
            "layout": "IPY_MODEL_2c016873590f44af89875ff868bf68ab"
          }
        },
        "8cba8b623e034191ae413efc82bb5d77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fa7294fc3f74d61adace3877be649ad",
            "placeholder": "​",
            "style": "IPY_MODEL_1207aed50abc4eec9149d530a2541018",
            "value": "Upload 1 LFS files: 100%"
          }
        },
        "a2a012e735ef460db24faedb1ea88da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd60dcaa03641f280dd993ecbd261bc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31f059c4e2ca4fc3b027b444bb4c409b",
            "value": 1
          }
        },
        "52f69431dd7c4202ae6d0a9170e89f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf37f6e8ec247a1a1dad582820a04c7",
            "placeholder": "​",
            "style": "IPY_MODEL_059d1acd16974213925a80ab184a88df",
            "value": " 1/1 [01:04&lt;00:00, 64.69s/it]"
          }
        },
        "2c016873590f44af89875ff868bf68ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fa7294fc3f74d61adace3877be649ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1207aed50abc4eec9149d530a2541018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cd60dcaa03641f280dd993ecbd261bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31f059c4e2ca4fc3b027b444bb4c409b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "baf37f6e8ec247a1a1dad582820a04c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059d1acd16974213925a80ab184a88df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af53b7a560fc48a0bc211f2a09b8584b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_189c51a51fa94422ad8c7c3375f25ff9",
              "IPY_MODEL_be086f4e03c049b6afaf6edd9b88a59d",
              "IPY_MODEL_d91153eb42874f6aa3dc790685f70dab"
            ],
            "layout": "IPY_MODEL_b8ecc6a54ea24ff3818120fb8c08374f"
          }
        },
        "189c51a51fa94422ad8c7c3375f25ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef327a671753405282ca212b757514d5",
            "placeholder": "​",
            "style": "IPY_MODEL_37785eda2b44416bb9101cf518effca5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "be086f4e03c049b6afaf6edd9b88a59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d68640591404e9e833b7d1a81411c4b",
            "max": 1625549581,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04c89a19fca44c27bc714a4bbe7d3274",
            "value": 1625549581
          }
        },
        "d91153eb42874f6aa3dc790685f70dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c2e7470f0fd45059cc7bac5d38888e0",
            "placeholder": "​",
            "style": "IPY_MODEL_bfc14bbc260f4014b5ae2b943a1db9ab",
            "value": " 1.63G/1.63G [01:04&lt;00:00, 22.1MB/s]"
          }
        },
        "b8ecc6a54ea24ff3818120fb8c08374f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef327a671753405282ca212b757514d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37785eda2b44416bb9101cf518effca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d68640591404e9e833b7d1a81411c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04c89a19fca44c27bc714a4bbe7d3274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c2e7470f0fd45059cc7bac5d38888e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc14bbc260f4014b5ae2b943a1db9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vSPt70wfhJxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51f5e543-57f2-4832-bfb2-99cb60ac4634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "uHzga6jl0ohS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = '/content/'"
      ],
      "metadata": {
        "id": "1LTHWUDDyDzW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 4 {DATA_PATH}train.wp_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fOnL_mycg4",
        "outputId": "0eed7b80-3d2a-4062-ede3-ae5f1a2e12c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open '/content/train.wp_combined' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_FILE=DATA_PATH+'valid.wp_combined' # Use valid as train to minimize training time first\n",
        "TEST_FILE=DATA_PATH+'test.wp_combined'\n",
        "print(TRAIN_FILE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXxnFLr2yfrt",
        "outputId": "c68f90b6-4d04-4658-d7e2-c46692dc45fb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/valid.wp_combined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output\n",
        "# !ls"
      ],
      "metadata": {
        "id": "7v-Gu3ZzyhLv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!cp {TRAIN_FILE} . \n",
        "!cp {TEST_FILE} . \n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRIu4CDByiz5",
        "outputId": "9d5bb629-8027-43d4-d918-2fae3ff3a909"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: '/content/valid.wp_combined' and './valid.wp_combined' are the same file\n",
            "cp: '/content/test.wp_combined' and './test.wp_combined' are the same file\n",
            "output\tsample_data  test.wp_combined  train.wp_combined  valid.wp_combined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MvpForConditionalGeneration, MvpTokenizerFast, MvpConfig"
      ],
      "metadata": {
        "id": "pnxa-CMbzRsG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MVP language model and tokenizer\n",
        "model_config = MvpConfig.from_pretrained(\"RUCAIBox/mvp\")\n",
        "# model = MvpForCausalLM.from_pretrained(\"RUCAIBox/mvp\")\n",
        "tokenizer = MvpTokenizerFast.from_pretrained(\"RUCAIBox/mvp\")\n",
        "tokenizer.save_pretrained('.')\n",
        "!ls -sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe_y1TWRiNVL",
        "outputId": "4f02aa5d-124b-4de7-b06c-2bef0869f224"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 451M\n",
            "4.0K added_tokens.json\t4.0K special_tokens_map.json  403M train.wp_combined\n",
            "448K merges.txt\t\t 23M test.wp_combined\t       24M valid.wp_combined\n",
            "4.0K output\t\t4.0K tokenizer_config.json    780K vocab.json\n",
            "4.0K sample_data\t2.1M tokenizer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp *.json output\n",
        "!ls -sh output/*.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3mdd0dAy940",
        "outputId": "27acad16-b7a0-4c94-a0de-9aeeb51e6878"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0K output/added_tokens.json\t     2.1M output/tokenizer.json\n",
            "4.0K output/special_tokens_map.json  780K output/vocab.json\n",
            "4.0K output/tokenizer_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python transformers/examples/run_language_modeling.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBjJgBp8llpX",
        "outputId": "22a76ccd-84a7-49ae-874a-0d49de5d6329"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/transformers/examples/run_language_modeling.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python transformers/examples/run_generation.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LjWlQjFloln",
        "outputId": "f9a04352-5584-4f7c-9ced-782828eafd20"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/transformers/examples/run_generation.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MvpForConditionalGeneration.from_pretrained(\"RUCAIBox/mvp\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "mJ4gNSk4zC1n",
        "outputId": "eabd4807-f0d0-4c9f-b345-2fa22c2fe773"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a7e959c9d282>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMvpForConditionalGeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RUCAIBox/mvp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'MvpForConditionalGeneration' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ids = tokenizer.encode('[ WP ] Aliens have arrived , and ask for a single human to plead humanity case and save them from extinction <endprompts>')\n",
        "ids = np.array(ids)[np.newaxis]\n",
        "print(ids.shape)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    torch.tensor(ids),\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5 \n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n\"+\"===\"*10)\n",
        "  print(\"{}: {}\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr3nX8QEzfwc",
        "outputId": "e6cc4edb-499d-40a5-a17e-6f6c39c1f88e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 30)\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "1: </s><s><s><s>`` What's your name? ''\n",
            "\n",
            "`` I'm not a human. I don't know what you're talking about. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "2: </s><s><s><s>It's been a long time since I've written a prompt, but I thought I 'd give it a shot.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "3: </s><s>I've been working on this prompt for a while now, and I thought I 'd give it a shot, so here goes :\n",
            "\n",
            "---\n",
            "\n",
            "The aliens have arrived, and ask for a single human to plead humanity case and save them from extinction < endprompt</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "4: </s><s><s><s>`` What do you want? ''\n",
            "\n",
            "`` I want to save humanity, '' I said.\n",
            "\n",
            "The aliens looked at me in confusion. `` Are you sure you want to do this? '' They asked me. `` I'm not sure. '' I looked at them for a moment. `` Well, I don't know. I've never heard of it before, but I think I 'd like to see what it looks like. '' They looked at each other for a second, and then back at me. They stared at me for a long time, and I couldn't help but feel like I was going to burst into tears. I didn't want to tell them that I had no idea what they were talking about, but it was hard not to. I wasn't sure what to say, so I just said, `` I have no idea. ''</s>\n",
            "\n",
            "==============================\n",
            "5: </s><s><s><s>`` I'm sorry, I don't know what to say. ''\n",
            "\n",
            "`` You're not going to believe this, but it's true. We're going to be extinct in a few hundred years. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "CPU times: user 2min 3s, sys: 208 ms, total: 2min 3s\n",
            "Wall time: 2min 7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ids = tokenizer.encode('[ WP ] Magic exists , but the nature of it is unique to the user , like a fingerprint . <endprompts>',\n",
        "                      return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5 \n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n\"+\"===\"*10)\n",
        "  print(\"{}: {}\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RbCxTeU0Pxj",
        "outputId": "a45651b5-2945-4ecc-984f-ca471ac12d4c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "1: </s><s><s><s>`` Magic exists, but the nature of it is unique to the user, like a fingerprint. ''\n",
            "\n",
            "I'm not sure what that means.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "2: </s><s><s><s>`` Magic exists, but the nature of it is unique to the user, like a fingerprint. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "3: </s><s><s><s>I've been looking for a prompt for a while now. It's been a while since I've written anything, but I thought I 'd give it a shot. I'm not sure if it's a good idea or not.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "4: </s><s><s><s>It's been a long time since I've written a prompt, but I thought I 'd give it a shot. I'm not sure if it's good or not, but here goes.\n",
            "\n",
            "I've always wanted to write a prompt about magic, but haven't gotten around to it yet. I just don't know if I 'll ever have the time. I can't seem to come up with a good title for this prompt, so here goes :\n",
            "\n",
            "*Magic exists, but the nature of it is unique to the user, like a fingerprint. *</s>\n",
            "\n",
            "==============================\n",
            "5: </s><s><s>`` Magic exists, but the nature of it is unique to the user, like a fingerprint. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "CPU times: user 1min 30s, sys: 164 ms, total: 1min 30s\n",
            "Wall time: 1min 36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ids = tokenizer.encode('[ WP ] Naruto meets Sasuke in the Jonin exam, and both of them have a serious fight with sand monster. <endprompts>',\n",
        "                      return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5 \n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n\"+\"===\"*10)\n",
        "  print(\"{}: {}\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1HuMa_y0bsh",
        "outputId": "f62496db-bd20-4211-db69-95ce11a0db4d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "1: </s><s><s><s>I'm going to do this for the first time in a long time. I'm not sure if I 'll be able to finish it, but I 'd like to try.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "2: </s><s><s><s>`` Naruto, what's the matter? '' Sasuke asked.\n",
            "\n",
            "`` Well, Naruto, you're the one who's fighting the sand monster, right? '' Naruto replied. Sasuke nodded. `` I'm sorry, Naruto. ''\n",
            "\n",
            "Sasuke looked at Naruto and said, `` It's okay, I 'll take care of it. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "3: </s><s><s><s>Naruto and Sasuke meet in the hallway of the school. Naruto looks at Sasuke with a look of confusion on his face.\n",
            "\n",
            "`` What's going on? ''\n",
            "\n",
            "Sasuke looks at Naruto with a confused expression. `` I'm sorry, Naruto. I didn't mean to interrupt. I don't know what you're talking about. I was just wondering if you 'd like to have a look at the sand monster. It's a sand monster, right? ''</s>\n",
            "\n",
            "==============================\n",
            "4: </s><s><s><s>`` Naruto! ''\n",
            "\n",
            "\n",
            "`` Sasuke! Naruto! Naruto, are you okay? '' Sasuke asks.\n",
            "\n",
            "Naruto looks at him and says, `` I'm fine, I 'll be fine. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "5: </s><s><s><s>`` Naruto! Naruto! ''\n",
            "\n",
            "`` Sasuke! '' Naruto yells.\n",
            "\n",
            "Sasuke looks at Naruto with a confused look on his face. `` Naruto, Naruto, you're going to die! ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "CPU times: user 1min 55s, sys: 189 ms, total: 1min 56s\n",
            "Wall time: 2min 1s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ids = tokenizer.encode('[ WP ] It is a romantic story between a guy from downtown and a beautiful girl who is a millionare <endprompts>',\n",
        "                      return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5 \n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n\"+\"===\"*10)\n",
        "  print(\"{}: {}\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnNK1ZLS1-Vn",
        "outputId": "265ac723-861d-4781-ad65-78b544c1d640"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "1: </s><s>`` I'm sorry, I didn't mean to interrupt. ''\n",
            "\n",
            "`` I know, I know. It's just that I've been thinking a lot about you lately, and I really don't know what to do with myself. I mean, I just want to be with you. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "2: </s><s>`` I love you so much. ''\n",
            "\n",
            "`` You love me so much too, '' he said.\n",
            "\n",
            "She smiled. `` I don't know what you're talking about, '' she said. `` You're a millionare. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "3: </s><s><s>`` I'm sorry, I don't know what to say. ''\n",
            "\n",
            "`` You're a millionare, '' she said.\n",
            "\n",
            "She smiled. `` It's okay. You 'll be fine. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "4: </s><s><s><s>`` I'm sorry, I don't know what to say. ''\n",
            "\n",
            "`` It's okay, it's just that I've never been in a place like this before. You know, I haven't been here before. I mean, I live in the city, but I have never been this close to anyone. I just... I just wanted to be with you, '' he said.\n",
            "\n",
            "I looked up at him, and he looked down at me, and smiled. `` You're so beautiful, '' I said. `` I love you so much. '' He said, and I smiled back. `` So do I. ''</s>\n",
            "\n",
            "==============================\n",
            "5: </s><s>`` I'm a millionare! ''\n",
            "\n",
            "`` A millionare? '' She said with a smile.\n",
            "\n",
            "He looked at her and smiled. `` You're one of the millionare. '' He took her hand and kissed her on the lips. She looked at him and smiled again. He held her hand for a few seconds and then he walked away.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "CPU times: user 1min 19s, sys: 133 ms, total: 1min 19s\n",
            "Wall time: 1min 20s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ids = tokenizer.encode('[ WP ] Two god-like beings , disguised as old men , play a game of chess on a park bench to decide the final fate of humanity .<endprompts>',\n",
        "                      return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5 \n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n\"+\"===\"*10)\n",
        "  print(\"{}: {}\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LICQJduN2BqU",
        "outputId": "3ae151ed-00f9-4b86-e287-cefb52b1a92a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "1: </s><s><s>`` What is this? ''\n",
            "\n",
            "`` It's a game of chess. '' The old man said.\n",
            "\n",
            "The old man looked at the chess board. `` What is it? '' He asked. `` I don't know. I've never seen it before. '' He said. `` But it's going to be a long game. ''</s>\n",
            "\n",
            "==============================\n",
            "2: </s><s><s><s>`` I'm going to kill you. ''\n",
            "\n",
            "\n",
            "`` You're going to do what? '' The old man asked.\n",
            "\n",
            "The old man replied, `` I 'll kill you if you don't leave me alone. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "3: </s><s><s><s>`` I don't know what I'm going to do. ''\n",
            "\n",
            "`` You're not going to die, you're going to play chess. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "4: </s><s><s>`` Two god-like beings, disguised as old men, play a game of chess on a park bench to decide the final fate of humanity. ''\n",
            "\n",
            "The old men looked at each other and nodded.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "5: </s><s><s><s>`` I don't know what you're talking about. ''\n",
            "\n",
            "`` It's okay, it's all right. I'm just saying that I've never seen a game of chess like this before. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "CPU times: user 1min 5s, sys: 129 ms, total: 1min 5s\n",
            "Wall time: 1min 5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ids = tokenizer.encode('[ WP ] Write a happy story about a dog . <endprompts>',\n",
        "                      return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5 \n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n\"+\"===\"*10)\n",
        "  print(\"{}: {}\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjNoq-G62ZLe",
        "outputId": "e76667dc-9261-4d98-a165-10aa486b5a0f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "1: </s><s><s><s>I'm a dog, and I'm happy.\n",
            "\n",
            "I've always been happy. I've been happy ever since I was a puppy. I know I 'll always be happy. It's just that I can't seem to find the right words to describe it. I don't know if it's because I have a dog or because I am a dog. I just know that I am happy.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "2: </s><s><s><s>It's been a long time since I've had a dog. I'm not sure how long it has been since I last had one, but I don't know how long I 'll be able to keep this up.\n",
            "\n",
            "I've been thinking about it a lot lately. It's hard to believe that it's only been a year since I had my first dog, and I can't remember the last time I saw him. He's grown up so much, but he's still my best friend. I can 't believe how much I love him.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "3: </s><s><s><s>I'm a dog.\n",
            "\n",
            "I've always wanted a dog, but I've never been able to get one. I don't know why I'm so sad, I guess it's because I never really got the chance to grow up. I 'll never get to have a family, but it 'll be okay. I know it will be alright. I just can't help but think of all the things I 'd like to do with my life if I could. I wish I could just have a pet, but that's not going to happen.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "4: </s><s><s><s>`` I'm a dog. ''\n",
            "\n",
            "`` You're not a dog, you're a cat. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "5: </s><s><s><s>I'm a dog.\n",
            "\n",
            "I've always wanted to be a dog, but I've never had the chance. I'm not sure if it's because I have a family, or because I don't know what I want to do with my life, but the only thing I know for sure is that I love my life. It's not perfect, but it is what it is. I just wish I could have more time to spend with my family. I wish I had more time with my dog. I miss him so much. I can't wait to see what he 'll do with the rest of his life. I love him more than anything in the world. He's my best friend.</s>\n",
            "CPU times: user 2min 7s, sys: 234 ms, total: 2min 7s\n",
            "Wall time: 2min 12s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "ids = tokenizer.encode('[ WP ] Scientists found for the first time bacteria which can be alive even without Oxygen . <endprompts>',\n",
        "                      return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=1000, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5 \n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 900 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n\"+\"===\"*10)\n",
        "  print(\"{}: {}\".format(i+1, tokenizer.decode(sample_output, skip_special_tokens=False)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g12tF3Dl2cTS",
        "outputId": "38ee0392-b8cc-4b00-9fa7-897109b675fb"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "1: </s><s><s><s>`` What's the problem? ''\n",
            "\n",
            "`` I don't know, I'm not sure. It's just that I've never seen anything like it before. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "2: </s><s><s><s>`` Scientists found for the first time bacteria which can be alive even without Oxygen. ''\n",
            "\n",
            "`` What? '' I asked.\n",
            "\n",
            "\n",
            "The scientist shook his head. `` I don't know what you're talking about. '' He looked at me. `` It's not a bacteria, it's a bacteria that can live without oxygen. ''</s><pad><pad>\n",
            "\n",
            "==============================\n",
            "3: </s><s><s><s>`` Scientists have found for the first time bacteria which can be alive even without Oxygen. ''\n",
            "\n",
            "`` No, I don't know what you're talking about. ''</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "\n",
            "==============================\n",
            "4: </s><s><s><s>`` This is the first time we've found a bacteria that can live without Oxygen! ''\n",
            "\n",
            "`` What's going on? '' I asked the scientist.\n",
            "\n",
            "The scientist looked at me. `` It's not just bacteria, it's a species of bacteria! '' he said. `` Scientists have found that bacteria can be alive even without oxygen! ''</s>\n",
            "\n",
            "==============================\n",
            "5: </s><s><s><s>`` Scientists found for the first time bacteria which can be alive even without Oxygen. ''\n",
            "\n",
            "`` What's that? '' I asked. \n",
            " `` It's a bacteria that can live without oxygen, '' the scientist said.\n",
            "\n",
            "I'm not sure what he was talking about. I've never heard of such a thing before.</s><pad><pad><pad><pad>\n",
            "CPU times: user 2min 12s, sys: 260 ms, total: 2min 12s\n",
            "Wall time: 2min 28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mtranslate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csYjSTQxBhWe",
        "outputId": "00c2d771-a821-403f-b4f3-109316dbbc92"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mtranslate\n",
            "  Downloading mtranslate-1.8.tar.gz (2.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mtranslate\n",
            "  Building wheel for mtranslate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mtranslate: filename=mtranslate-1.8-py3-none-any.whl size=3697 sha256=821324420786912284e3343b7bb357ca740d3bb2f363ba405743b6ce0021b39e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/04/15/d7654c2c4a9a52e09922967593f3278fed66059be65ca671ea\n",
            "Successfully built mtranslate\n",
            "Installing collected packages: mtranslate\n",
            "Successfully installed mtranslate-1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mtranslate\n",
        "translator = mtranslate.translate\n",
        "# Translate English to French\n",
        "translated_text = mtranslate.translate(\"Hello, how are you?\", to_language=\"fr\")\n",
        "\n",
        "print(f\"Translated text: {translated_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTdiPMEZCsXx",
        "outputId": "deb2f435-f33d-42e7-d057-368fa19048f8"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translated text: Bonjour comment allez-vous?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "th_stories = ['[ WP ] Tôi là sinh viên đại học Tôn Đức Thắng <endprompts>',\n",
        "             '[ WP ] Tôi có những người bạn tuyệt vời <endprompts>',\n",
        "             '[ WP ] Hôm nay tôi phải báo cáo cuối kỳ môn học sâu <endprompts>',]"
      ],
      "metadata": {
        "id": "DhEMKKhA4vSJ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_input=th_stories[0]\n",
        "new_input = mtranslate.translate(orig_input, to_language='en')\n",
        "\n",
        "ids = tokenizer.encode(new_input, return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5\n",
        ")\n",
        "print(\"Input: %s\\n\\n\" % orig_input)\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    out = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "    new_out_en = mtranslate.translate(out, to_language='en') # Dịch đầu ra từ Tiếng Anh sang Tiếng Việt\n",
        "    new_out = mtranslate.translate(new_out_en, to_language='vi') # Dịch đầu ra từ Tiếng Việt sang Tiếng Anh\n",
        "    print(\"\\n\"+\"===\"*10)\n",
        "    print(\"Ví dụ{}: {}\\n\".format(i+1, new_out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NNZAjoYM-cc",
        "outputId": "0c964dbb-dedb-4c7f-a472-de7f76b02a8e"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [ WP ] Tôi là sinh viên đại học Tôn Đức Thắng <endprompts>\n",
            "\n",
            "\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "Ví dụ1: Tôi là sinh viên trường Đại học Tôn Đức Thắng.\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ2: Đã lâu lắm rồi tôi mới gặp lại bạn. Tôi chắc rằng bạn đã mong chờ ngày này từ rất lâu rồi.\n",
            "\n",
            "Em sắp làm giáo viên trường đại học Tôn Đức Thắng, nhưng không biết có được không. Tôi không biết phải làm gì với cuộc sống của mình. Tôi chỉ muốn trở thành giáo viên tốt nhất mà tôi có thể trở thành. Tôi biết tôi có thể làm được, nhưng nó sẽ mất rất nhiều công sức. Chỉ là vấn đề thời gian trước khi tôi tìm ra những gì tôi muốn làm.\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ3: Tôi là sinh viên trường đại học Tôn Đức Thắng\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ4: Tôi là sinh viên trường đại học Tôn Đức Thắng\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ5: Tôi là sinh viên trường đại học Tôn Đức Thắng\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_input=th_stories[2]\n",
        "new_input = mtranslate.translate(orig_input, to_language='en')\n",
        "\n",
        "ids = tokenizer.encode(new_input, return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5\n",
        ")\n",
        "print(\"Input: %s\\n\\n\" % orig_input)\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    out = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "    new_out_en = mtranslate.translate(out, to_language='en') # Dịch đầu ra từ Tiếng Anh sang Tiếng Việt\n",
        "    new_out = mtranslate.translate(new_out_en, to_language='vi') # Dịch đầu ra từ Tiếng Việt sang Tiếng Anh\n",
        "    print(\"\\n\"+\"===\"*10)\n",
        "    print(\"Ví dụ{}: {}\\n\".format(i+1, new_out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DIVXaCoJ9m_",
        "outputId": "033069d6-afb4-4e81-b2c1-fce1057f3077"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [ WP ] Tôi có những người bạn tuyệt vời <endprompts>\n",
            "\n",
            "\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "Ví dụ1: Tôi sẽ đăng bài này như một lời nhắc. Tôi có một người bạn là một người bạn tuyệt vời của tôi. Tôi không chắc đó là bạn tốt hay bạn xấu nhưng tôi không biết.\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ2: Tôi đã có một số người bạn tuyệt vời. Tôi không chắc họ có phải là bạn của tôi hay không, nhưng tôi không nghĩ họ sẽ là bạn của tôi.\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ3: Tôi có những người bạn tuyệt vời.\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ4: `` Tôi có những người bạn tuyệt vời. ' Tôi nói với chính mình.\n",
            "\n",
            "`` Tôi không biết tại sao bạn lại nói như vậy. '' Anh ấy nói. `` Bạn là một người bạn tuyệt vời. ''\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ5: `` Tôi có những người bạn tuyệt vời. ''\n",
            "\n",
            "`` Tôi không biết ý của bạn là gì. ''\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orig_input=th_stories[2]\n",
        "new_input = mtranslate.translate(orig_input, to_language='en')\n",
        "\n",
        "ids = tokenizer.encode(new_input, return_tensors='pt')\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "    ids,\n",
        "    do_sample=True, \n",
        "    max_length=300, \n",
        "    top_k=55, \n",
        "    top_p=0.925, \n",
        "    num_return_sequences=5\n",
        ")\n",
        "print(\"Input: %s\\n\\n\" % orig_input)\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    out = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "    new_out_en = mtranslate.translate(out, to_language='en') # Dịch đầu ra từ Tiếng Anh sang Tiếng Việt\n",
        "    new_out = mtranslate.translate(new_out_en, to_language='vi') # Dịch đầu ra từ Tiếng Việt sang Tiếng Anh\n",
        "    print(\"\\n\"+\"===\"*10)\n",
        "    print(\"Ví dụ{}: {}\\n\".format(i+1, new_out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omXVpwhaSzfZ",
        "outputId": "238c1767-4e3d-4f44-aeab-9bcb794038f3"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: [ WP ] Tôi có những người bạn tuyệt vời <endprompts>\n",
            "\n",
            "\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "==============================\n",
            "Ví dụ1: Tôi không chắc đó là một ý tưởng tốt hay một ý tưởng tồi, nhưng dù sao thì tôi cũng sẽ làm. Tôi đã có ý định viết điều này cho một thời gian bây giờ. Tôi không biết liệu mình có bao giờ làm được không.\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ2: `` Tôi có những người bạn tuyệt vời. ''\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ3: Tôi có rất nhiều người bạn tuyệt vời.\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ4: ``Tôi có những người bạn tuyệt vời''\n",
            "\n",
            "`` Tôi không biết ý của bạn là gì, '' tôi nói. `` Tôi đã không gặp bạn trong một thời gian dài. ''\n",
            "\n",
            "\n",
            "==============================\n",
            "Ví dụ5: `` Tôi có những người bạn tuyệt vời! ''\n",
            "\n",
            "`` Tôi không biết bạn đang nói về cái gì. ''\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "ZM5bNiEZTg7i"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "________________________________________________________________________________"
      ],
      "metadata": {
        "id": "fUY71TVL0XWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def evaluate_bleu_score(stories, num_samples=1000):\n",
        "    bleu_scores = []\n",
        "    for story in tqdm(stories[:num_samples]):\n",
        "        orig_input = story\n",
        "        new_input = mtranslate.translate(orig_input, to_language='en')\n",
        "\n",
        "        ids = tokenizer.encode(new_input, return_tensors='pt')\n",
        "        ids = ids.to('cuda') # Move the ids tensor to GPU\n",
        "\n",
        "        model.eval()\n",
        "        model.to('cuda')\n",
        "        sample_outputs = model.generate(\n",
        "            ids,\n",
        "            do_sample=True, \n",
        "            max_length=300, \n",
        "            top_k=55, \n",
        "            top_p=0.925, \n",
        "            num_return_sequences=5\n",
        "        )\n",
        "\n",
        "        for i, sample_output in enumerate(sample_outputs):\n",
        "            out = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "            new_out_en = mtranslate.translate(out, to_language='en') # Dịch đầu ra từ Tiếng Anh sang Tiếng Việt\n",
        "            new_out = mtranslate.translate(new_out_en, to_language='vi') # Dịch đầu ra từ Tiếng Việt sang Tiếng Anh\n",
        "            bleu_score = sentence_bleu([orig_input], new_out)\n",
        "            bleu_scores.append(bleu_score)\n",
        "    return bleu_scores\n",
        "\n",
        "bleu_scores = evaluate_bleu_score(th_stories)\n",
        "print(\"Average BLEU score: %.4f\" % np.mean(bleu_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lsYKcZOVtyy",
        "outputId": "c7292efa-68ea-4eeb-a46f-60bf531175aa"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:11<00:00,  3.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU score: 0.3676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def evaluate_bleu_score(stories, num_samples=1000):\n",
        "    bleu_scores = []\n",
        "    for story in tqdm(stories[:num_samples]):\n",
        "        orig_input = story\n",
        "        \n",
        "\n",
        "        ids = tokenizer.encode(orig_input, return_tensors='pt')\n",
        "        ids = ids.to('cuda') # Move the ids tensor to GPU\n",
        "\n",
        "        model.eval()\n",
        "        model.to('cuda')\n",
        "        sample_outputs = model.generate(\n",
        "          ids,\n",
        "          do_sample=True, \n",
        "          max_length=300, \n",
        "          top_k=55, \n",
        "          top_p=0.925, \n",
        "          num_return_sequences=5 \n",
        "        )\n",
        "\n",
        "        for i, sample_output in enumerate(sample_outputs):\n",
        "            out = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "            bleu_score = sentence_bleu([orig_input], out)\n",
        "            bleu_scores.append(bleu_score)\n",
        "    return bleu_scores\n",
        "\n",
        "bleu_scores = evaluate_bleu_score(TEST_FILE)\n",
        "print(\"Average BLEU score: %.4f\" % np.mean(bleu_scores))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oMNI_XmWtqy",
        "outputId": "fa5d3812-8c3b-491a-8460-0a1957770ffe"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 25/25 [00:18<00:00,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average BLEU score: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login"
      ],
      "metadata": {
        "id": "t1AtkfbeancS"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "login('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')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "norW6vlwalQN",
        "outputId": "0fa5b483-91b3-493e-e7cf-8c1124b51df6"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub('NTN09/MVP_tao_lao')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "d48e56ad4d6b4a119b2d55965cb7c872",
            "8cba8b623e034191ae413efc82bb5d77",
            "a2a012e735ef460db24faedb1ea88da8",
            "52f69431dd7c4202ae6d0a9170e89f53",
            "2c016873590f44af89875ff868bf68ab",
            "9fa7294fc3f74d61adace3877be649ad",
            "1207aed50abc4eec9149d530a2541018",
            "7cd60dcaa03641f280dd993ecbd261bc",
            "31f059c4e2ca4fc3b027b444bb4c409b",
            "baf37f6e8ec247a1a1dad582820a04c7",
            "059d1acd16974213925a80ab184a88df",
            "af53b7a560fc48a0bc211f2a09b8584b",
            "189c51a51fa94422ad8c7c3375f25ff9",
            "be086f4e03c049b6afaf6edd9b88a59d",
            "d91153eb42874f6aa3dc790685f70dab",
            "b8ecc6a54ea24ff3818120fb8c08374f",
            "ef327a671753405282ca212b757514d5",
            "37785eda2b44416bb9101cf518effca5",
            "1d68640591404e9e833b7d1a81411c4b",
            "04c89a19fca44c27bc714a4bbe7d3274",
            "2c2e7470f0fd45059cc7bac5d38888e0",
            "bfc14bbc260f4014b5ae2b943a1db9ab"
          ]
        },
        "id": "WfuYSReVa7UZ",
        "outputId": "ea55feb4-3ac2-484e-afea-1d2770c5fbb9"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d48e56ad4d6b4a119b2d55965cb7c872"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af53b7a560fc48a0bc211f2a09b8584b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/NTN09/MVP_tao_lao/commit/e5ff3c7380d3658f0b41b0db490baa6cecf7ae61', commit_message='Upload MvpForConditionalGeneration', commit_description='', oid='e5ff3c7380d3658f0b41b0db490baa6cecf7ae61', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub('NTN09/MVP_tao_lao', private=True, use_auth_token=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHbQukjbbM6n",
        "outputId": "cc06632e-a930-4fe7-bbdd-aa525535c03f"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/NTN09/MVP_tao_lao/commit/10e1fc8153b135a113e9eb3d7dde7f455357c3f7', commit_message='Upload tokenizer', commit_description='', oid='10e1fc8153b135a113e9eb3d7dde7f455357c3f7', pr_url=None, pr_revision=None, pr_num=None)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    }
  ]
}